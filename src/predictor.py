"""
Predictor Module for F&B Process Anomaly Detection System
Honeywell Hackathon Solution

This module provides:
1. Real-time quality prediction
2. Anomaly detection
3. Process monitoring
4. Alert generation
5. Recommendation system
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import warnings
import joblib
import json
from datetime import datetime, timedelta
from loguru import logger

from src.config import (
    MODEL_DIR, PROCESS_PARAMS, QUALITY_THRESHOLDS, ALERT_CONFIG
)

warnings.filterwarnings('ignore')

class Predictor:
    """
    Comprehensive predictor for F&B process anomaly detection.
    Provides real-time predictions and anomaly detection.
    """
    
    def __init__(self, model_path: Optional[str] = None, anomaly_path: Optional[str] = None):
        self.quality_model = None
        self.anomaly_detector = None
        self.scaler = None
        self.selected_features = []
        self.model_metadata = {}
        self.alert_history = []
        self.prediction_history = []
        
        # Load models if paths provided
        if model_path or anomaly_path:
            self.load_models(model_path, anomaly_path)
        
        logger.info("Predictor initialized")
    
    def load_models(self, model_path: Optional[str] = None, anomaly_path: Optional[str] = None):
        """Load trained models from disk."""
        try:
            # Auto-detect model files if not provided
            if not model_path:
                model_files = list(MODEL_DIR.glob("*quality*.pkl"))
                if model_files:
                    model_path = str(max(model_files, key=lambda x: x.stat().st_mtime))
            
            if not anomaly_path:
                anomaly_files = list(MODEL_DIR.glob("*anomaly*.pkl"))
                if anomaly_files:
                    anomaly_path = str(max(anomaly_files, key=lambda x: x.stat().st_mtime))
            
            # Load quality model
            if model_path and Path(model_path).exists():
                self.quality_model = joblib.load(model_path)
                logger.info(f"Quality model loaded from {model_path}")
            
            # Load anomaly detector
            if anomaly_path and Path(anomaly_path).exists():
                self.anomaly_detector = joblib.load(anomaly_path)
                logger.info(f"Anomaly detector loaded from {anomaly_path}")
            
            # Load scaler
            scaler_files = list(MODEL_DIR.glob("*scaler*.pkl"))
            if scaler_files:
                scaler_path = str(max(scaler_files, key=lambda x: x.stat().st_mtime))
                self.scaler = joblib.load(scaler_path)
                logger.info(f"Scaler loaded from {scaler_path}")
            
            # Load selected features
            features_file = Path("data/processed/selected_features.txt")
            if features_file.exists():
                with open(features_file, 'r') as f:
                        self.selected_features = [line.strip() for line in f.readlines() if line.strip()]
                logger.info(f"Loaded {len(self.selected_features)} selected features")
            
            # Load model metadata
            metadata_files = list(MODEL_DIR.glob("*results*.json"))
            if metadata_files:
                metadata_path = str(max(metadata_files, key=lambda x: x.stat().st_mtime))
                with open(metadata_path, 'r') as f:
                            self.model_metadata = json.load(f)
                logger.info(f"Model metadata loaded from {metadata_path}")
            
        except Exception as e:
            logger.error(f"Error loading models: {e}")
    
    def predict_batch(self, batch_features: pd.DataFrame) -> Dict:
        """
        Make predictions for a batch of features.
        
        Args:
            batch_features: DataFrame with engineered features
        
        Returns:
            Dictionary containing predictions, anomalies, and recommendations
        """
        try:
            # Prepare features
            X = self._prepare_features(batch_features)
            
            # Make quality predictions
            quality_predictions = self._predict_quality(X)
            
            # Detect anomalies
            anomaly_results = self._detect_anomalies(X)
            
            # Assess quality
            quality_assessment = self._assess_quality(quality_predictions)
            
            # Generate recommendations
            recommendations = self._generate_recommendations(
                quality_predictions, anomaly_results, quality_assessment
            )
            
            # Create alert if needed
            alert = self._create_alert(quality_predictions, anomaly_results, quality_assessment)
            
            # Store prediction history
            prediction_record = {
                'timestamp': datetime.now().isoformat(),
                'predictions': quality_predictions,
                'anomalies': anomaly_results,
                'assessment': quality_assessment,
                'alert': alert
            }
            self.prediction_history.append(prediction_record)
            
            return {
                'predictions': quality_predictions,
                'anomalies': anomaly_results,
                'quality_assessment': quality_assessment,
                'recommendations': recommendations,
                'alert': alert,
                'timestamp': datetime.now().isoformat(),
                'model_info': self.get_model_info()
            }
            
        except Exception as e:
            logger.error(f"Prediction error: {e}")
            return self._error_response(str(e))
    
    def predict_realtime(self, process_data: pd.DataFrame) -> Dict:
        """
        Make real-time predictions for streaming process data.
        
        Args:
            process_data: Real-time process parameters
        
        Returns:
            Dictionary containing real-time predictions
        """
        try:
            # Extract features from real-time data
            features = self._extract_realtime_features(process_data)
            
            # Make prediction
            result = self.predict_batch(features)
            
            # Add real-time specific information
            result['realtime'] = True
            result['data_freshness'] = 'live'
            result['processing_time'] = datetime.now().isoformat()
            
            return result
            
        except Exception as e:
            logger.error(f"Real-time prediction error: {e}")
            return self._error_response(str(e))
    
    def _prepare_features(self, batch_features: pd.DataFrame) -> pd.DataFrame:
        """Prepare features for prediction."""
        # Use selected features if available
        if self.selected_features:
            available_features = [f for f in self.selected_features if f in batch_features.columns]
            if available_features:
                X = batch_features[available_features].copy()
            else:
                # Fallback to all numeric features
                X = batch_features.select_dtypes(include=[np.number]).copy()
        else:
            # Use all numeric features
            X = batch_features.select_dtypes(include=[np.number]).copy()
        
        # Remove target columns if present
        target_cols = ['Final_Weight', 'Quality_Score']
        X = X.drop(columns=[col for col in target_cols if col in X.columns], errors='ignore')
        
        # Handle missing values
        X = X.fillna(X.mean())
        
        # Scale features if scaler is available
        if self.scaler is not None:
            try:
                X_scaled = self.scaler.transform(X)
                X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)
            except Exception as e:
                logger.warning(f"Scaling failed: {e}")
        
        return X
    
    def _predict_quality(self, X: pd.DataFrame) -> Dict:
        """Make quality predictions using the trained model."""
        if self.quality_model is None:
            # Fallback predictions
            return {
                'weight': 50.0 + np.random.normal(0, 1),
                'quality': 85.0 + np.random.normal(0, 3)
            }
    
        try:
            predictions = self.quality_model.predict(X)
            
            # Handle different prediction formats
            if len(predictions.shape) > 1 and predictions.shape[1] >= 2:
                # Multi-output model
                weight_pred = float(predictions[0, 0])
                quality_pred = float(predictions[0, 1])
            else:
                # Single output - assume quality, estimate weight
                quality_pred = float(predictions[0])
                weight_pred = self._estimate_weight_from_features(X.iloc[0])
            
            return {
                'weight': weight_pred,
                'quality': quality_pred
            }
            
        except Exception as e:
            logger.error(f"Quality prediction error: {e}")
            return {
                'weight': 50.0,
                'quality': 85.0
            }
    
    def _detect_anomalies(self, X: pd.DataFrame) -> Dict:
        """Detect anomalies using the trained detector."""
        if self.anomaly_detector is None:
            # Fallback anomaly detection
            return {
                'is_anomaly': np.random.random() < 0.05,
                'anomaly_score': np.random.normal(0, 0.3),
                'risk_level': 'low'
            }
    
        try:
            # Get anomaly scores and labels
            anomaly_scores = self.anomaly_detector.score_samples(X)
            anomaly_labels = self.anomaly_detector.predict(X)
            
            is_anomaly = bool(anomaly_labels[0] == -1)
            anomaly_score = float(anomaly_scores[0])
            
            # Determine risk level
            if is_anomaly:
                if anomaly_score < -0.5:
                    risk_level = 'high'
                elif anomaly_score < -0.2:
                    risk_level = 'medium'
                else:
                    risk_level = 'low'
            else:
                risk_level = 'low'
            
            return {
                'is_anomaly': is_anomaly,
                'anomaly_score': anomaly_score,
                'risk_level': risk_level
            }
            
        except Exception as e:
            logger.error(f"Anomaly detection error: {e}")
        return {
                'is_anomaly': False,
                'anomaly_score': 0.0,
                'risk_level': 'low'
            }
    
    def _assess_quality(self, predictions: Dict) -> Dict:
        """Assess quality based on predictions and thresholds."""
        weight = predictions.get('weight', 50.0)
        quality = predictions.get('quality', 85.0)
        
        # Weight assessment
        weight_status = 'pass'
        if weight < QUALITY_THRESHOLDS['weight']['min'] or weight > QUALITY_THRESHOLDS['weight']['max']:
            weight_status = 'fail'
        elif weight < QUALITY_THRESHOLDS['weight']['critical_low'] or weight > QUALITY_THRESHOLDS['weight']['critical_high']:
            weight_status = 'critical'
        
        # Quality assessment
        quality_status = 'pass'
        if quality < QUALITY_THRESHOLDS['quality_score']['min']:
            quality_status = 'fail'
        elif quality < QUALITY_THRESHOLDS['quality_score']['critical']:
            quality_status = 'critical'
        
        # Overall assessment
        if weight_status == 'pass' and quality_status == 'pass':
            overall_status = 'pass'
        elif weight_status == 'critical' or quality_status == 'critical':
            overall_status = 'critical'
        else:
            overall_status = 'fail'
        
        return {
            'weight_status': weight_status,
            'quality_status': quality_status,
            'overall_status': overall_status,
            'weight_deviation': abs(weight - QUALITY_THRESHOLDS['weight']['ideal']) / QUALITY_THRESHOLDS['weight']['ideal'] * 100,
            'quality_deviation': abs(quality - QUALITY_THRESHOLDS['quality_score']['ideal']) / QUALITY_THRESHOLDS['quality_score']['ideal'] * 100
        }
    
    def _generate_recommendations(self, predictions: Dict, anomalies: Dict, assessment: Dict) -> List[str]:
        """Generate actionable recommendations."""
        recommendations = []
        
        weight = predictions.get('weight', 50.0)
        quality = predictions.get('quality', 85.0)
        
        # Weight-based recommendations
        if weight < QUALITY_THRESHOLDS['weight']['min']:
            recommendations.append("‚ö†Ô∏è Increase ingredient quantities - product underweight")
        elif weight > QUALITY_THRESHOLDS['weight']['max']:
            recommendations.append("‚ö†Ô∏è Reduce ingredient quantities - product overweight")
        
        # Quality-based recommendations
        if quality < QUALITY_THRESHOLDS['quality_score']['min']:
            recommendations.append("üî• Check oven temperature settings - quality below standard")
            recommendations.append("‚è∞ Verify fermentation time and conditions")
            recommendations.append("üå°Ô∏è Monitor mixing temperature consistency")
        
        # Anomaly-based recommendations
        if anomalies.get('is_anomaly', False):
            risk_level = anomalies.get('risk_level', 'low')
            if risk_level == 'high':
                recommendations.append("üö® CRITICAL ANOMALY - Immediate supervisor review required")
                recommendations.append("üõë Consider stopping production for investigation")
            elif risk_level == 'medium':
                recommendations.append("‚ö†Ô∏è ANOMALY DETECTED - Enhanced monitoring required")
                recommendations.append("üìä Check all process parameters against specifications")
            else:
                recommendations.append("üìà Minor anomaly detected - Continue with caution")
        
        # Process-specific recommendations
        if assessment['overall_status'] == 'critical':
            recommendations.append("üîß Perform equipment maintenance check")
            recommendations.append("üìã Review standard operating procedures")
        
        # Default recommendation
        if not recommendations:
            recommendations.append("‚úÖ Process operating within normal parameters")
        
        return recommendations
    
    def _create_alert(self, predictions: Dict, anomalies: Dict, assessment: Dict) -> Optional[Dict]:
        """Create alert if conditions warrant."""
        alert = None
        
        # Check for critical conditions
        if (assessment['overall_status'] == 'critical' or 
            anomalies.get('risk_level') == 'high' or
            anomalies.get('is_anomaly', False)):
            
            alert = {
                'level': 'critical' if assessment['overall_status'] == 'critical' else 'warning',
                'message': f"Quality issue detected: Weight={predictions.get('weight', 0):.1f}kg, Quality={predictions.get('quality', 0):.1f}%",
                'timestamp': datetime.now().isoformat(),
                'recommendations': self._generate_recommendations(predictions, anomalies, assessment)
            }
            
            # Add to alert history
            self.alert_history.append(alert)
            
            # Limit alert history
            if len(self.alert_history) > 100:
                self.alert_history = self.alert_history[-100:]
        
        return alert
    
    def _extract_realtime_features(self, process_data: pd.DataFrame) -> pd.DataFrame:
        """Extract features from real-time process data."""
        # This is a simplified version - in practice, you'd use the same feature engineering
        # as the training process
        features = {}
        
        for param in PROCESS_PARAMS.keys():
            if param in process_data.columns:
                value = process_data[param].iloc[-1]  # Latest value
                param_clean = param.replace(' ', '_').replace('(', '').replace(')', '').replace('%', 'pct')
                features[f'{param_clean}_mean'] = value
                features[f'{param_clean}_std'] = 0  # No variation in single point
                features[f'{param_clean}_deviation'] = (value - PROCESS_PARAMS[param]['ideal']) / PROCESS_PARAMS[param]['ideal'] * 100
        
        return pd.DataFrame([features])
    
    def _estimate_weight_from_features(self, features: pd.Series) -> float:
        """Estimate weight from process features."""
        # Simple heuristic based on ingredient quantities
        if 'Flour_kg_mean' in features:
            base_weight = float(features['Flour_kg_mean'])
            return base_weight * 1.1 + np.random.normal(0, 0.5)
        else:
            return 50.0 + np.random.normal(0, 1)
    
    def _error_response(self, error_msg: str) -> Dict:
        """Generate error response."""
        return {
            'predictions': {'weight': 50.0, 'quality': 85.0},
            'anomalies': {'is_anomaly': False, 'anomaly_score': 0.0, 'risk_level': 'low'},
            'quality_assessment': {'overall_status': 'unknown'},
            'recommendations': ['Check system status'],
            'alert': None,
            'timestamp': datetime.now().isoformat(),
            'error': error_msg
        }
    
    def get_model_info(self) -> Dict:
        """Get information about loaded models."""
        return {
            'quality_model_loaded': self.quality_model is not None,
            'anomaly_detector_loaded': self.anomaly_detector is not None,
            'scaler_loaded': self.scaler is not None,
            'selected_features_count': len(self.selected_features),
            'model_metadata': self.model_metadata,
            'prediction_history_count': len(self.prediction_history),
            'alert_history_count': len(self.alert_history)
        }
    
    def get_alert_history(self, limit: int = 10) -> List[Dict]:
        """Get recent alert history."""
        return self.alert_history[-limit:]
    
    def get_prediction_history(self, limit: int = 10) -> List[Dict]:
        """Get recent prediction history."""
        return self.prediction_history[-limit:]
    
    def clear_history(self):
        """Clear prediction and alert history."""
        self.prediction_history = []
        self.alert_history = []
        logger.info("Prediction and alert history cleared")
    
    def get_system_status(self) -> Dict:
        """Get overall system status."""
        return {
            'status': 'operational' if self.quality_model is not None else 'degraded',
            'models_loaded': self.get_model_info(),
            'last_prediction': self.prediction_history[-1] if self.prediction_history else None,
            'recent_alerts': len([a for a in self.alert_history if a['level'] == 'critical']),
            'timestamp': datetime.now().isoformat()
        }
