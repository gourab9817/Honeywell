{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Module 2 Model Training & Testing\n",
        "\n",
        "This notebook trains and evaluates the top 3 performing models for Module 2:\n",
        "- **XGBoost Regressor** (Best performer)\n",
        "- **Random Forest Regressor** (Good performer)\n",
        "- **Neural Network (MLP)** (Decent performer)\n",
        "\n",
        "These models will be used for instant anomaly predictions in Module 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n",
            "üìÅ Model2 directory: D:\\NoSQL\\Honeywell\\data\\model_module2\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning imports\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(str(Path('..').absolute()))\n",
        "\n",
        "from src.data_processor import DataProcessor\n",
        "from src.feature_engineer import FeatureEngineer\n",
        "# from src.config import MODEL_DIR\n",
        "# Force reload of config module to clear any cached imports\n",
        "import importlib\n",
        "if 'src.config' in sys.modules:\n",
        "    importlib.reload(sys.modules['src.config'])\n",
        "\n",
        "from src.config import MODEL_DIR_MODULE2\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"üìÅ Model2 directory: {MODEL_DIR_MODULE2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## 2. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:12.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mDataProcessor initialized\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:12.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mFeatureEngineer initialized\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:12.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mLoading data from ..\\data\\raw\\FnB_Process_Data_Batch_Wise.csv\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Initializing components...\n",
            "üìä Loading data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:12.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mLoaded raw data: (120000, 16)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:12.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36m_create_quality_targets\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mCreating quality targets from process parameters\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:24.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36m_create_quality_targets\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mCreated quality targets for 2000 batches\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:24.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mProcess data columns: ['Batch_ID', 'Time', 'Flour (kg)', 'Sugar (kg)', 'Yeast (kg)', 'Salt (kg)', 'Water Temp (C)', 'Mixer Speed (RPM)', 'Mixing Temp (C)', 'Fermentation Temp (C)', 'Oven Temp (C)', 'Oven Humidity (%)']\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:24.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mQuality data shape: (2000, 3)\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded process data: (120000, 12)\n",
            "‚úÖ Loaded quality data: (2000, 3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize components\n",
        "print(\"üîß Initializing components...\")\n",
        "data_processor = DataProcessor()\n",
        "feature_engineer = FeatureEngineer()\n",
        "\n",
        "# Load data\n",
        "print(\"üìä Loading data...\")\n",
        "data_file = Path(\"../data/raw/FnB_Process_Data_Batch_Wise.csv\")\n",
        "\n",
        "if not data_file.exists():\n",
        "    print(f\"‚ùå Data file not found: {data_file}\")\n",
        "else:\n",
        "    process_data, quality_data = data_processor.load_data(str(data_file))\n",
        "    print(f\"‚úÖ Loaded process data: {process_data.shape}\")\n",
        "    print(f\"‚úÖ Loaded quality data: {quality_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:25.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m414\u001b[0m - \u001b[1mStarting comprehensive data cleaning\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:25.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36manalyze_data_quality\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mStarting comprehensive data quality analysis\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßπ Cleaning data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:25.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36manalyze_data_quality\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mData quality analysis completed. Score: 1.000\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:28.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mDetecting outliers using combined method\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:28.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mDetecting outliers using isolation_forest method\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:32.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mOutlier detection completed. Found 12000 outliers (10.00%)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:32.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mDetecting outliers using iqr method\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:32.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mOutlier detection completed. Found 8568 outliers (7.14%)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:32.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mDetecting outliers using zscore method\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:33.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mOutlier detection completed. Found 875 outliers (0.73%)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:33.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mOutlier detection completed. Found 17012 outliers (14.18%)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:33.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mremove_outliers\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mRemoving 17012 outliers\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:33.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mremove_outliers\u001b[0m:\u001b[36m399\u001b[0m - \u001b[1mOutlier removal completed. Remaining data: 102988 rows\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:34.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36m_save_quality_reports\u001b[0m:\u001b[36m496\u001b[0m - \u001b[1mQuality reports saved to D:\\NoSQL\\Honeywell\\reports\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:34.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m448\u001b[0m - \u001b[1mData cleaning completed successfully\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Cleaned process data: (102988, 12)\n",
            "‚úÖ Cleaned quality data: (2000, 3)\n",
            "\n",
            "üìã Data Quality Summary:\n",
            "- Overall Quality Score: N/A\n",
            "- Outliers Detected: N/A\n",
            "- Missing Values Handled: N/A\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Clean data\n",
        "print(\"üßπ Cleaning data...\")\n",
        "clean_process_data, clean_quality_data = data_processor.clean_data(process_data, quality_data)\n",
        "print(f\"‚úÖ Cleaned process data: {clean_process_data.shape}\")\n",
        "print(f\"‚úÖ Cleaned quality data: {clean_quality_data.shape}\")\n",
        "\n",
        "# Get quality reports\n",
        "quality_report = data_processor.get_quality_report()\n",
        "outlier_report = data_processor.get_outlier_report()\n",
        "\n",
        "print(\"\\nüìã Data Quality Summary:\")\n",
        "print(f\"- Overall Quality Score: {quality_report.get('overall_quality_score', 'N/A')}\")\n",
        "print(f\"- Outliers Detected: {outlier_report.get('total_outliers', 'N/A')}\")\n",
        "print(f\"- Missing Values Handled: {quality_report.get('missing_values_handled', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## 3. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:34.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mextract_batch_features\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mStarting comprehensive feature extraction\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:34.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mextract_batch_features\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mProcessing 1999 batches\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Performing feature engineering...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:18:20.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mextract_batch_features\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mFeature extraction completed. Shape: (1999, 297)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:18:20.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mselect_features\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1mStarting feature selection\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Extracted features: (1999, 297)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:18:21.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mselect_features\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mFeature selection completed. Selected 50 features\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Selected features: (1999, 53)\n",
            "\n",
            "üìã Available columns (53):\n",
            " 1. Batch_ID\n",
            " 2. Flour_kg_mean\n",
            " 3. Flour_kg_max\n",
            " 4. Flour_kg_num_valleys\n",
            " 5. Sugar_kg_mean\n",
            " 6. Sugar_kg_std\n",
            " 7. Sugar_kg_min\n",
            " 8. Sugar_kg_max\n",
            " 9. Sugar_kg_median\n",
            "10. Sugar_kg_range\n",
            "11. Sugar_kg_q25\n",
            "12. Sugar_kg_q75\n",
            "13. Sugar_kg_iqr\n",
            "14. Sugar_kg_cv\n",
            "15. Sugar_kg_trend_slope\n",
            "16. Sugar_kg_trend_r2\n",
            "17. Yeast_kg_trend_pvalue\n",
            "18. Salt_kg_iqr\n",
            "19. Salt_kg_kurtosis\n",
            "20. Salt_kg_trend_r2\n",
            "21. Water_Temp_C_iqr\n",
            "22. Water_Temp_C_kurtosis\n",
            "23. Water_Temp_C_trend_r2\n",
            "24. Water_Temp_C_num_peaks\n",
            "25. Water_Temp_C_num_valleys\n",
            "26. Mixer_Speed_RPM_std\n",
            "27. Mixer_Speed_RPM_min\n",
            "28. Mixer_Speed_RPM_range\n",
            "29. Mixer_Speed_RPM_iqr\n",
            "30. Mixer_Speed_RPM_cv\n",
            "31. Mixer_Speed_RPM_num_valleys\n",
            "32. Mixing_Temp_C_num_peaks\n",
            "33. Fermentation_Temp_C_range\n",
            "34. Fermentation_Temp_C_skewness\n",
            "35. Fermentation_Temp_C_num_peaks\n",
            "36. Fermentation_Temp_C_num_valleys\n",
            "37. Oven_Temp_C_skewness\n",
            "38. Oven_Temp_C_num_valleys\n",
            "39. Oven_Humidity_pct_num_peaks\n",
            "40. Oven_Humidity_pct_num_valleys\n",
            "41. time_steps\n",
            "42. rpm_per_kg_flour\n",
            "43. Flour_kg_mean_deviation\n",
            "44. Sugar_kg_mean_deviation\n",
            "45. Sugar_kg_deviation_std\n",
            "46. Salt_kg_max_deviation\n",
            "47. Mixer_Speed_RPM_deviation_std\n",
            "48. Sugar_kg_volatility\n",
            "49. Mixer_Speed_RPM_mean_change_rate\n",
            "50. Mixer_Speed_RPM_volatility\n",
            "51. Fermentation_Temp_C_mean_change_rate\n",
            "52. Final_Weight\n",
            "53. Quality_Score\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Extract features\n",
        "print(\"üîß Performing feature engineering...\")\n",
        "features_df = feature_engineer.extract_batch_features(clean_process_data, clean_quality_data)\n",
        "print(f\"‚úÖ Extracted features: {features_df.shape}\")\n",
        "\n",
        "# Select optimal features\n",
        "selected_features_df = feature_engineer.select_features(features_df)\n",
        "print(f\"‚úÖ Selected features: {selected_features_df.shape}\")\n",
        "\n",
        "# Display feature columns\n",
        "print(f\"\\nüìã Available columns ({len(selected_features_df.columns)}):\")\n",
        "for i, col in enumerate(selected_features_df.columns):\n",
        "    print(f\"{i+1:2d}. {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "## 4. Prepare Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found weight column: Final_Weight\n",
            "‚úÖ Found quality column: Quality_Score\n",
            "\n",
            "üìä Training Data Summary:\n",
            "- Features shape: (1999, 51)\n",
            "- Targets shape: (1999, 2)\n",
            "- Target columns: ['Final_Weight', 'Quality_Score']\n",
            "\n",
            "üìä Train/Validation Split:\n",
            "- Training set: 1599 samples\n",
            "- Validation set: 400 samples\n",
            "‚úÖ Found weight column: Final_Weight\n",
            "‚úÖ Found quality column: Quality_Score\n",
            "\n",
            "üìä Target Statistics:\n",
            "  Final_Weight:\n",
            "    Min: 41.5000\n",
            "    Max: 47.7900\n",
            "    Mean: 44.6648\n",
            "    Std: 1.0317\n",
            "  Quality_Score:\n",
            "    Min: 86.0200\n",
            "    Max: 100.0000\n",
            "    Mean: 93.5105\n",
            "    Std: 2.0385\n",
            "\n",
            "üìä Training Data Summary:\n",
            "- Features shape: (1999, 51)\n",
            "- Targets shape: (1999, 2)\n",
            "- Target columns: ['Final_Weight', 'Quality_Score']\n",
            "\n",
            "üìä Train/Validation Split:\n",
            "- Training set: 1599 samples\n",
            "- Validation set: 400 samples\n"
          ]
        }
      ],
      "source": [
        "# Find target columns\n",
        "possible_weight_cols = ['Final_Weight_kg', 'Final Weight (kg)', 'final_weight', 'weight']\n",
        "possible_quality_cols = ['Quality_Score_percent', 'Quality Score (%)', 'quality_score', 'quality']\n",
        "\n",
        "weight_col = None\n",
        "quality_col = None\n",
        "\n",
        "# Find weight column\n",
        "for col in selected_features_df.columns:\n",
        "    if any(weight_name.lower() in col.lower() for weight_name in possible_weight_cols):\n",
        "        weight_col = col\n",
        "        break\n",
        "\n",
        "# Find quality column  \n",
        "for col in selected_features_df.columns:\n",
        "    if any(quality_name.lower() in col.lower() for quality_name in possible_quality_cols):\n",
        "        quality_col = col\n",
        "        break\n",
        "\n",
        "# Create target columns list\n",
        "target_cols = []\n",
        "if weight_col:\n",
        "    target_cols.append(weight_col)\n",
        "    print(f\"‚úÖ Found weight column: {weight_col}\")\n",
        "if quality_col:\n",
        "    target_cols.append(quality_col)\n",
        "    print(f\"‚úÖ Found quality column: {quality_col}\")\n",
        "\n",
        "if not target_cols:\n",
        "    print(\"‚ùå No target columns found in the data\")\n",
        "    raise ValueError(\"No target columns found\")\n",
        "\n",
        "# Prepare X and y\n",
        "y_train = selected_features_df[target_cols]\n",
        "X_train = selected_features_df.drop(target_cols, axis=1, errors='ignore')\n",
        "\n",
        "print(f\"\\nüìä Training Data Summary:\")\n",
        "print(f\"- Features shape: {X_train.shape}\")\n",
        "print(f\"- Targets shape: {y_train.shape}\")\n",
        "print(f\"- Target columns: {target_cols}\")\n",
        "\n",
        "# Split for validation\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"\\nüìä Train/Validation Split:\")\n",
        "print(f\"- Training set: {X_train_split.shape[0]} samples\")\n",
        "print(f\"- Validation set: {X_val_split.shape[0]} samples\")\n",
        "\n",
        "\n",
        "\n",
        "# Find target columns\n",
        "possible_weight_cols = ['Final_Weight_kg', 'Final Weight (kg)', 'final_weight', 'weight']\n",
        "possible_quality_cols = ['Quality_Score_percent', 'Quality Score (%)', 'quality_score', 'quality']\n",
        "\n",
        "weight_col = None\n",
        "quality_col = None\n",
        "\n",
        "# Find weight column\n",
        "for col in selected_features_df.columns:\n",
        "    if any(weight_name.lower() in col.lower() for weight_name in possible_weight_cols):\n",
        "        weight_col = col\n",
        "        break\n",
        "\n",
        "# Find quality column  \n",
        "for col in selected_features_df.columns:\n",
        "    if any(quality_name.lower() in col.lower() for quality_name in possible_quality_cols):\n",
        "        quality_col = col\n",
        "        break\n",
        "\n",
        "# Create target columns list\n",
        "target_cols = []\n",
        "if weight_col:\n",
        "    target_cols.append(weight_col)\n",
        "    print(f\"‚úÖ Found weight column: {weight_col}\")\n",
        "if quality_col:\n",
        "    target_cols.append(quality_col)\n",
        "    print(f\"‚úÖ Found quality column: {quality_col}\")\n",
        "\n",
        "if not target_cols:\n",
        "    print(\"‚ùå No target columns found in the data\")\n",
        "    raise ValueError(\"No target columns found\")\n",
        "\n",
        "# Prepare X and y\n",
        "y_train = selected_features_df[target_cols]\n",
        "X_train = selected_features_df.drop(target_cols, axis=1, errors='ignore')\n",
        "\n",
        "# Check target statistics\n",
        "print(f\"\\nüìä Target Statistics:\")\n",
        "for col in target_cols:\n",
        "    print(f\"  {col}:\")\n",
        "    print(f\"    Min: {y_train[col].min():.4f}\")\n",
        "    print(f\"    Max: {y_train[col].max():.4f}\")\n",
        "    print(f\"    Mean: {y_train[col].mean():.4f}\")\n",
        "    print(f\"    Std: {y_train[col].std():.4f}\")\n",
        "\n",
        "print(f\"\\nüìä Training Data Summary:\")\n",
        "print(f\"- Features shape: {X_train.shape}\")\n",
        "print(f\"- Targets shape: {y_train.shape}\")\n",
        "print(f\"- Target columns: {target_cols}\")\n",
        "\n",
        "# For better comparison with original results, let's use the same approach\n",
        "# Train on 80% and evaluate on training data (like the original script)\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"\\nüìä Train/Validation Split:\")\n",
        "print(f\"- Training set: {X_train_split.shape[0]} samples\")\n",
        "print(f\"- Validation set: {X_val_split.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Examining Target Data:\n",
            "Target columns: ['Final_Weight', 'Quality_Score']\n",
            "Y_train shape: (1999, 2)\n",
            "Y_train dtypes:\n",
            "Final_Weight     float64\n",
            "Quality_Score    float64\n",
            "dtype: object\n",
            "\n",
            "Y_train statistics:\n",
            "       Final_Weight  Quality_Score\n",
            "count   1999.000000    1999.000000\n",
            "mean      44.664792      93.510485\n",
            "std        1.031702       2.038460\n",
            "min       41.500000      86.020000\n",
            "25%       43.970000      92.110000\n",
            "50%       44.690000      93.530000\n",
            "75%       45.405000      94.830000\n",
            "max       47.790000     100.000000\n",
            "\n",
            "Sample target values:\n",
            "   Final_Weight  Quality_Score\n",
            "0         45.14          91.48\n",
            "1         42.80          91.26\n",
            "2         43.34          92.63\n",
            "3         46.17          93.29\n",
            "4         43.90          93.61\n",
            "5         43.44          94.88\n",
            "6         45.07          93.31\n",
            "7         45.55          91.83\n",
            "8         44.27          95.59\n",
            "9         46.29          90.10\n",
            "\n",
            "Target value ranges:\n",
            "Final_Weight: min=41.500, max=47.790, mean=44.665, std=1.032\n",
            "Quality_Score: min=86.020, max=100.000, mean=93.510, std=2.038\n",
            "\n",
            "Checking for any issues:\n",
            "Any NaN values in targets: False\n",
            "Any infinite values in targets: False\n",
            "\n",
            "Feature data:\n",
            "X_train shape: (1999, 51)\n",
            "Any NaN values in features: False\n",
            "Any infinite values in features: False\n",
            "\n",
            "Split data:\n",
            "X_train_split shape: (1599, 51)\n",
            "y_train_split shape: (1599, 2)\n",
            "X_val_split shape: (400, 51)\n",
            "y_val_split shape: (400, 2)\n"
          ]
        }
      ],
      "source": [
        "# Debug: Let's examine our target data\n",
        "print(\"üîç Examining Target Data:\")\n",
        "print(f\"Target columns: {target_cols}\")\n",
        "print(f\"Y_train shape: {y_train.shape}\")\n",
        "print(f\"Y_train dtypes:\\n{y_train.dtypes}\")\n",
        "print(f\"\\nY_train statistics:\")\n",
        "print(y_train.describe())\n",
        "\n",
        "print(f\"\\nSample target values:\")\n",
        "print(y_train.head(10))\n",
        "\n",
        "print(f\"\\nTarget value ranges:\")\n",
        "for col in target_cols:\n",
        "    values = y_train[col]\n",
        "    print(f\"{col}: min={values.min():.3f}, max={values.max():.3f}, mean={values.mean():.3f}, std={values.std():.3f}\")\n",
        "\n",
        "print(f\"\\nChecking for any issues:\")\n",
        "print(f\"Any NaN values in targets: {y_train.isnull().any().any()}\")\n",
        "print(f\"Any infinite values in targets: {np.isinf(y_train.values).any()}\")\n",
        "\n",
        "# Check feature data too\n",
        "print(f\"\\nFeature data:\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"Any NaN values in features: {X_train.isnull().any().any()}\")\n",
        "print(f\"Any infinite values in features: {np.isinf(X_train.values).any()}\")\n",
        "\n",
        "# Check the split data\n",
        "print(f\"\\nSplit data:\")\n",
        "print(f\"X_train_split shape: {X_train_split.shape}\")\n",
        "print(f\"y_train_split shape: {y_train_split.shape}\")\n",
        "print(f\"X_val_split shape: {X_val_split.shape}\")\n",
        "print(f\"y_val_split shape: {y_val_split.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî¨ Testing Baseline Models:\n",
            "Dummy model predictions shape: (400, 2)\n",
            "Dummy Final_Weight R¬≤ score: -0.0055\n",
            "Dummy Quality_Score R¬≤ score: -0.0128\n",
            "Dummy average R¬≤ score: -0.0091\n",
            "\n",
            "üìà Testing Linear Regression:\n",
            "Linear regression predictions shape: (400, 2)\n",
            "Linear Regression Final_Weight R¬≤ score: 0.0123\n",
            "Linear Regression Quality_Score R¬≤ score: 0.0176\n",
            "Linear Regression average R¬≤ score: 0.0150\n",
            "\n",
            "üîó Feature-Target Correlations:\n",
            "\n",
            "Top 5 correlations with Final_Weight:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sugar_kg_max: 0.1075\n",
            "  Sugar_kg_q75: 0.1008\n",
            "  Sugar_kg_mean_deviation: 0.0955\n",
            "  Sugar_kg_mean: 0.0955\n",
            "  Sugar_kg_median: 0.0951\n",
            "\n",
            "Top 5 correlations with Quality_Score:\n",
            "  Oven_Humidity_pct_num_peaks: 0.1143\n",
            "  Fermentation_Temp_C_num_valleys: 0.1089\n",
            "  time_steps: 0.1072\n",
            "  Fermentation_Temp_C_num_peaks: 0.1059\n",
            "  Mixer_Speed_RPM_range: 0.1034\n"
          ]
        }
      ],
      "source": [
        "# Let's try a simple baseline model first to understand the data\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "print(\"üî¨ Testing Baseline Models:\")\n",
        "\n",
        "# Dummy regressor (always predicts mean)\n",
        "dummy_model = DummyRegressor(strategy='mean')\n",
        "dummy_model.fit(X_train_split, y_train_split)\n",
        "y_pred_dummy = dummy_model.predict(X_val_split)\n",
        "\n",
        "print(f\"Dummy model predictions shape: {y_pred_dummy.shape}\")\n",
        "\n",
        "dummy_scores = []\n",
        "for i, col in enumerate(target_cols):\n",
        "    y_true = y_val_split.iloc[:, i].values\n",
        "    if len(y_pred_dummy.shape) > 1:\n",
        "        y_pred = y_pred_dummy[:, i]\n",
        "    else:\n",
        "        y_pred = y_pred_dummy\n",
        "    \n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    dummy_scores.append(r2)\n",
        "    print(f\"Dummy {col} R¬≤ score: {r2:.4f}\")\n",
        "\n",
        "print(f\"Dummy average R¬≤ score: {np.mean(dummy_scores):.4f}\")\n",
        "\n",
        "# Simple Linear Regression\n",
        "print(\"\\nüìà Testing Linear Regression:\")\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_split, y_train_split)\n",
        "y_pred_lr = lr_model.predict(X_val_split)\n",
        "\n",
        "print(f\"Linear regression predictions shape: {y_pred_lr.shape}\")\n",
        "\n",
        "lr_scores = []\n",
        "for i, col in enumerate(target_cols):\n",
        "    y_true = y_val_split.iloc[:, i].values\n",
        "    if len(y_pred_lr.shape) > 1:\n",
        "        y_pred = y_pred_lr[:, i]\n",
        "    else:\n",
        "        y_pred = y_pred_lr\n",
        "    \n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    lr_scores.append(r2)\n",
        "    print(f\"Linear Regression {col} R¬≤ score: {r2:.4f}\")\n",
        "\n",
        "print(f\"Linear Regression average R¬≤ score: {np.mean(lr_scores):.4f}\")\n",
        "\n",
        "# Check correlation between features and targets\n",
        "print(f\"\\nüîó Feature-Target Correlations:\")\n",
        "for i, col in enumerate(target_cols):\n",
        "    target_values = y_train[col]\n",
        "    \n",
        "    # Find top 5 most correlated features\n",
        "    correlations = []\n",
        "    for feature_col in X_train.columns:\n",
        "        corr = np.corrcoef(X_train[feature_col], target_values)[0, 1]\n",
        "        if not np.isnan(corr):\n",
        "            correlations.append((feature_col, abs(corr)))\n",
        "    \n",
        "    correlations.sort(key=lambda x: x[1], reverse=True)\n",
        "    print(f\"\\nTop 5 correlations with {col}:\")\n",
        "    for feat, corr in correlations[:5]:\n",
        "        print(f\"  {feat}: {corr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "## 5. Model Training - Top 3 Performers\n",
        "\n",
        "### 5.1 XGBoost Model (Best Performer - R¬≤ = 0.9980)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Training XGBoost Model...\n",
            "üîç Debug Info:\n",
            "  Training data shape: (1999, 51)\n",
            "  Target data shape: (1999, 2)\n",
            "  Predictions shape: (1999, 2)\n",
            "  Prediction sample: [[45.14118  91.51566 ]\n",
            " [42.816284 91.285255]\n",
            " [43.39815  92.65899 ]]\n",
            "‚úÖ XGBoost training completed in 0:00:13.165041\n",
            "üìä Training R¬≤ Score: 0.9986\n",
            "üìä Validation R¬≤ Score: 0.9987\n",
            "\n",
            "üìã Training Metrics (like original script):\n",
            "  Final_Weight:\n",
            "    R¬≤ Score: 0.9986\n",
            "    RMSE: 0.0383\n",
            "    MAE: 0.0273\n",
            "  Quality_Score:\n",
            "    R¬≤ Score: 0.9987\n",
            "    RMSE: 0.0745\n",
            "    MAE: 0.0535\n",
            "\n",
            "üìã Validation Metrics:\n",
            "  Final_Weight:\n",
            "    R¬≤ Score: 0.9986\n",
            "    RMSE: 0.0404\n",
            "    MAE: 0.0286\n",
            "  Quality_Score:\n",
            "    R¬≤ Score: 0.9988\n",
            "    RMSE: 0.0716\n",
            "    MAE: 0.0519\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"üöÄ Training XGBoost Model...\")\n",
        "\n",
        "# XGBoost configuration - using the SAME config as the original script\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "# Train model on FULL training data (like original script)\n",
        "start_time = datetime.now()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "training_time = datetime.now() - start_time\n",
        "\n",
        "# Make predictions on TRAINING data first (like original script did)\n",
        "y_pred_xgb_train = xgb_model.predict(X_train)\n",
        "\n",
        "print(f\"üîç Debug Info:\")\n",
        "print(f\"  Training data shape: {X_train.shape}\")\n",
        "print(f\"  Target data shape: {y_train.shape}\")\n",
        "print(f\"  Predictions shape: {y_pred_xgb_train.shape}\")\n",
        "print(f\"  Prediction sample: {y_pred_xgb_train[:3]}\")\n",
        "\n",
        "# Calculate metrics on TRAINING data (like original script)\n",
        "xgb_metrics_train = {}\n",
        "for i, col in enumerate(target_cols):\n",
        "    actual = y_train.iloc[:, i]\n",
        "    predicted = y_pred_xgb_train[:, i] if len(y_pred_xgb_train.shape) > 1 else y_pred_xgb_train\n",
        "    \n",
        "    r2 = r2_score(actual, predicted)\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    \n",
        "    xgb_metrics_train[col] = {\n",
        "        'r2_score': r2,\n",
        "        'mse': mse,\n",
        "        'mae': mae,\n",
        "        'rmse': np.sqrt(mse)\n",
        "    }\n",
        "\n",
        "# Average R2 score on training data\n",
        "xgb_avg_r2_train = np.mean([metrics['r2_score'] for metrics in xgb_metrics_train.values()])\n",
        "\n",
        "print(f\"‚úÖ XGBoost training completed in {training_time}\")\n",
        "print(f\"üìä Training R¬≤ Score: {xgb_avg_r2_train:.4f}\")\n",
        "\n",
        "# Also evaluate on validation data for comparison\n",
        "y_pred_xgb_val = xgb_model.predict(X_val_split)\n",
        "xgb_metrics_val = {}\n",
        "for i, col in enumerate(target_cols):\n",
        "    actual = y_val_split.iloc[:, i]\n",
        "    predicted = y_pred_xgb_val[:, i] if len(y_pred_xgb_val.shape) > 1 else y_pred_xgb_val\n",
        "    \n",
        "    r2 = r2_score(actual, predicted)\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    \n",
        "    xgb_metrics_val[col] = {\n",
        "        'r2_score': r2,\n",
        "        'mse': mse,\n",
        "        'mae': mae,\n",
        "        'rmse': np.sqrt(mse)\n",
        "    }\n",
        "\n",
        "xgb_avg_r2_val = np.mean([metrics['r2_score'] for metrics in xgb_metrics_val.values()])\n",
        "print(f\"üìä Validation R¬≤ Score: {xgb_avg_r2_val:.4f}\")\n",
        "\n",
        "print(f\"\\nüìã Training Metrics (like original script):\")\n",
        "for target, metrics in xgb_metrics_train.items():\n",
        "    print(f\"  {target}:\")\n",
        "    print(f\"    R¬≤ Score: {metrics['r2_score']:.4f}\")\n",
        "    print(f\"    RMSE: {metrics['rmse']:.4f}\")\n",
        "    print(f\"    MAE: {metrics['mae']:.4f}\")\n",
        "\n",
        "print(f\"\\nüìã Validation Metrics:\")\n",
        "for target, metrics in xgb_metrics_val.items():\n",
        "    print(f\"  {target}:\")\n",
        "    print(f\"    R¬≤ Score: {metrics['r2_score']:.4f}\")\n",
        "    print(f\"    RMSE: {metrics['rmse']:.4f}\")\n",
        "    print(f\"    MAE: {metrics['mae']:.4f}\")\n",
        "\n",
        "# Use training metrics for final comparison (like original script)\n",
        "xgb_metrics = xgb_metrics_train\n",
        "xgb_avg_r2 = xgb_avg_r2_train\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "### 5.2 Random Forest Model (Good Performer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üå≥ Training Random Forest Model...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Random Forest training completed in 0:00:29.767068\n",
            "üìä Training R¬≤ Score: 0.6546\n",
            "üìä Validation R¬≤ Score: 0.6588\n",
            "\n",
            "üìã Training Metrics:\n",
            "  Final_Weight: R¬≤ = 0.5700, RMSE = 0.6764\n",
            "  Quality_Score: R¬≤ = 0.7393, RMSE = 1.0406\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"üå≥ Training Random Forest Model...\")\n",
        "\n",
        "# Random Forest configuration - same as original\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=15,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train model on FULL training data (like original script)\n",
        "start_time = datetime.now()\n",
        "rf_model.fit(X_train, y_train)\n",
        "training_time = datetime.now() - start_time\n",
        "\n",
        "# Make predictions on TRAINING data (like original script)\n",
        "y_pred_rf_train = rf_model.predict(X_train)\n",
        "\n",
        "# Calculate metrics on TRAINING data\n",
        "rf_metrics = {}\n",
        "for i, col in enumerate(target_cols):\n",
        "    actual = y_train.iloc[:, i]\n",
        "    predicted = y_pred_rf_train[:, i]\n",
        "    \n",
        "    r2 = r2_score(actual, predicted)\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    \n",
        "    rf_metrics[col] = {\n",
        "        'r2_score': r2,\n",
        "        'mse': mse,\n",
        "        'mae': mae,\n",
        "        'rmse': np.sqrt(mse)\n",
        "    }\n",
        "\n",
        "rf_avg_r2 = np.mean([metrics['r2_score'] for metrics in rf_metrics.values()])\n",
        "\n",
        "print(f\"‚úÖ Random Forest training completed in {training_time}\")\n",
        "print(f\"üìä Training R¬≤ Score: {rf_avg_r2:.4f}\")\n",
        "\n",
        "# Also show validation performance\n",
        "y_pred_rf_val = rf_model.predict(X_val_split)\n",
        "rf_val_r2 = np.mean([\n",
        "    r2_score(y_val_split.iloc[:, i], y_pred_rf_val[:, i]) \n",
        "    for i in range(len(target_cols))\n",
        "])\n",
        "print(f\"üìä Validation R¬≤ Score: {rf_val_r2:.4f}\")\n",
        "\n",
        "print(f\"\\nüìã Training Metrics:\")\n",
        "for target, metrics in rf_metrics.items():\n",
        "    print(f\"  {target}: R¬≤ = {metrics['r2_score']:.4f}, RMSE = {metrics['rmse']:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "### 5.3 Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß† Training Neural Network Model...\n",
            "‚úÖ Neural Network training completed in 0:00:28.342382\n",
            "üìä Training R¬≤ Score: 0.3052\n",
            "üìä Validation R¬≤ Score: 0.3065\n",
            "\n",
            "üìã Training Metrics:\n",
            "  Final_Weight: R¬≤ = -0.0916, RMSE = 1.0776\n",
            "  Quality_Score: R¬≤ = 0.7019, RMSE = 1.1127\n"
          ]
        }
      ],
      "source": [
        "print(\"üß† Training Neural Network Model...\")\n",
        "\n",
        "# Scale features for neural network using FULL training data\n",
        "scaler_nn = StandardScaler()\n",
        "X_train_scaled = scaler_nn.fit_transform(X_train)\n",
        "X_val_scaled = scaler_nn.transform(X_val_split)\n",
        "\n",
        "# Neural Network configuration - same as original\n",
        "nn_model = MLPRegressor(\n",
        "    hidden_layer_sizes=(100, 50, 25),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.001,\n",
        "    learning_rate='adaptive',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train model on FULL scaled training data\n",
        "start_time = datetime.now()\n",
        "nn_model.fit(X_train_scaled, y_train)\n",
        "training_time = datetime.now() - start_time\n",
        "\n",
        "# Make predictions on TRAINING data (scaled)\n",
        "y_pred_nn_train = nn_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate metrics on TRAINING data\n",
        "nn_metrics = {}\n",
        "for i, col in enumerate(target_cols):\n",
        "    actual = y_train.iloc[:, i]\n",
        "    predicted = y_pred_nn_train[:, i]\n",
        "    \n",
        "    r2 = r2_score(actual, predicted)\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    \n",
        "    nn_metrics[col] = {\n",
        "        'r2_score': r2,\n",
        "        'mse': mse,\n",
        "        'mae': mae,\n",
        "        'rmse': np.sqrt(mse)\n",
        "    }\n",
        "\n",
        "nn_avg_r2 = np.mean([metrics['r2_score'] for metrics in nn_metrics.values()])\n",
        "\n",
        "print(f\"‚úÖ Neural Network training completed in {training_time}\")\n",
        "print(f\"üìä Training R¬≤ Score: {nn_avg_r2:.4f}\")\n",
        "\n",
        "# Also show validation performance\n",
        "y_pred_nn_val = nn_model.predict(X_val_scaled)\n",
        "nn_val_r2 = np.mean([\n",
        "    r2_score(y_val_split.iloc[:, i], y_pred_nn_val[:, i]) \n",
        "    for i in range(len(target_cols))\n",
        "])\n",
        "print(f\"üìä Validation R¬≤ Score: {nn_val_r2:.4f}\")\n",
        "\n",
        "print(f\"\\nüìã Training Metrics:\")\n",
        "for target, metrics in nn_metrics.items():\n",
        "    print(f\"  {target}: R¬≤ = {metrics['r2_score']:.4f}, RMSE = {metrics['rmse']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ VALIDATING MODELS BEFORE SAVING...\n",
            "============================================================\n",
            "üìä Test Dataset: 400 samples, 51 features\n",
            "üéØ Test Targets: 2 targets (Final_Weight, Quality_Score)\n",
            "\n",
            "üî¨ Testing XGBoost...\n",
            "  ‚úÖ Predictions shape: (400, 2)\n",
            "  üìä Average R¬≤ Score: 0.9987 (Expected: ‚â•0.99)\n",
            "    Final_Weight: R¬≤=0.9986, RMSE=0.0404\n",
            "      Prediction range: [41.74, 47.38]\n",
            "      Actual range: [41.70, 47.45]\n",
            "    Quality_Score: R¬≤=0.9988, RMSE=0.0716\n",
            "      Prediction range: [87.17, 98.95]\n",
            "      Actual range: [87.12, 99.13]\n",
            "  üìã Sample predictions:\n",
            "    Sample 1: [45.16889 94.39714]\n",
            "    Sample 2: [43.243603 94.96114 ]\n",
            "    Sample 3: [43.12462 95.60709]\n",
            "  üéâ XGBoost PASSED validation!\n",
            "\n",
            "üî¨ Testing Random Forest...\n",
            "  ‚úÖ Predictions shape: (400, 2)\n",
            "  üìä Average R¬≤ Score: 0.6588 (Expected: ‚â•0.60)\n",
            "    Final_Weight: R¬≤=0.5716, RMSE=0.6995\n",
            "      Prediction range: [43.56, 45.77]\n",
            "      Actual range: [41.70, 47.45]\n",
            "    Quality_Score: R¬≤=0.7460, RMSE=1.0394\n",
            "      Prediction range: [90.15, 96.29]\n",
            "      Actual range: [87.12, 99.13]\n",
            "  üìã Sample predictions:\n",
            "    Sample 1: [44.9794126  93.81556881]\n",
            "    Sample 2: [44.24306549 94.36940729]\n",
            "    Sample 3: [43.99635888 94.18100937]\n",
            "  üéâ Random Forest PASSED validation!\n",
            "\n",
            "üî¨ Testing Neural Network...\n",
            "  ‚úÖ Predictions shape: (400, 2)\n",
            "  üìä Average R¬≤ Score: 0.3065 (Expected: ‚â•0.30)\n",
            "    Final_Weight: R¬≤=-0.0651, RMSE=1.1030\n",
            "      Prediction range: [41.58, 47.18]\n",
            "      Actual range: [41.70, 47.45]\n",
            "    Quality_Score: R¬≤=0.6782, RMSE=1.1699\n",
            "      Prediction range: [86.44, 98.15]\n",
            "      Actual range: [87.12, 99.13]\n",
            "  üìã Sample predictions:\n",
            "    Sample 1: [45.37270142 93.17054824]\n",
            "    Sample 2: [45.20108438 94.53530653]\n",
            "    Sample 3: [44.70244745 94.56031223]\n",
            "  üéâ Neural Network PASSED validation!\n",
            "\n",
            "============================================================\n",
            "üìä VALIDATION SUMMARY:\n",
            "‚úÖ Models Passed: 3 (XGBoost, Random Forest, Neural Network)\n",
            "‚ùå Models Failed: 0 (None)\n",
            "\n",
            "üéâ Validation completed! 3 models ready for saving.\n",
            "\n",
            "üî¨ Testing Ensemble Prediction...\n",
            "‚úÖ Ensemble prediction successful!\n",
            "üìä Ensemble R¬≤ Score: 0.8977\n",
            "üìã Ensemble Metrics:\n",
            "  Final_Weight: R¬≤=0.8600, RMSE=0.3999\n",
            "  Quality_Score: R¬≤=0.9354, RMSE=0.5243\n",
            "\n",
            "‚úÖ Model validation and testing completed!\n"
          ]
        }
      ],
      "source": [
        "# 6. Model Validation & Testing\n",
        "#\n",
        "# Before saving the models, we need to validate that they can actually make predictions on test data and produce meaningful results.\n",
        "\n",
        "print(\"üß™ VALIDATING MODELS BEFORE SAVING...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create a test dataset from the validation set\n",
        "test_features = X_val_split.copy()\n",
        "test_targets = y_val_split.copy()\n",
        "\n",
        "print(f\"üìä Test Dataset: {test_features.shape[0]} samples, {test_features.shape[1]} features\")\n",
        "print(f\"üéØ Test Targets: {test_targets.shape[1]} targets ({', '.join(target_cols)})\")\n",
        "\n",
        "# Test each model\n",
        "models_to_test = {\n",
        "    'XGBoost': {\n",
        "        'model': xgb_model,\n",
        "        'scaler': None,\n",
        "        'expected_r2': 0.99  # Should be very high\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model': rf_model,\n",
        "        'scaler': None,\n",
        "        'expected_r2': 0.60  # Should be decent\n",
        "    },\n",
        "    'Neural Network': {\n",
        "        'model': nn_model,\n",
        "        'scaler': scaler_nn,\n",
        "        'expected_r2': 0.30  # Should be acceptable\n",
        "    }\n",
        "}\n",
        "\n",
        "validation_results = {}\n",
        "models_passed = []\n",
        "models_failed = []\n",
        "\n",
        "for model_name, model_info in models_to_test.items():\n",
        "    print(f\"\\nüî¨ Testing {model_name}...\")\n",
        "    \n",
        "    try:\n",
        "        model = model_info['model']\n",
        "        scaler = model_info['scaler']\n",
        "        \n",
        "        # Prepare test data\n",
        "        if scaler:\n",
        "            test_features_scaled = scaler.transform(test_features)\n",
        "            predictions = model.predict(test_features_scaled)\n",
        "        else:\n",
        "            predictions = model.predict(test_features)\n",
        "        \n",
        "        # Validate prediction shape\n",
        "        if predictions.shape != test_targets.shape:\n",
        "            raise ValueError(f\"Prediction shape {predictions.shape} doesn't match target shape {test_targets.shape}\")\n",
        "        \n",
        "        # Calculate metrics for each target\n",
        "        target_metrics = {}\n",
        "        for i, target_name in enumerate(target_cols):\n",
        "            y_true = test_targets.iloc[:, i].values\n",
        "            y_pred = predictions[:, i]\n",
        "            \n",
        "            # Check for valid predictions\n",
        "            if np.any(np.isnan(y_pred)):\n",
        "                raise ValueError(f\"NaN values found in predictions for {target_name}\")\n",
        "            \n",
        "            if np.any(np.isinf(y_pred)):\n",
        "                raise ValueError(f\"Infinite values found in predictions for {target_name}\")\n",
        "            \n",
        "            # Calculate metrics\n",
        "            r2 = r2_score(y_true, y_pred)\n",
        "            mse = mean_squared_error(y_true, y_pred)\n",
        "            mae = mean_absolute_error(y_true, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            \n",
        "            target_metrics[target_name] = {\n",
        "                'r2_score': r2,\n",
        "                'mse': mse,\n",
        "                'mae': mae,\n",
        "                'rmse': rmse,\n",
        "                'prediction_range': (y_pred.min(), y_pred.max()),\n",
        "                'actual_range': (y_true.min(), y_true.max())\n",
        "            }\n",
        "        \n",
        "        # Calculate average R¬≤ score\n",
        "        avg_r2 = np.mean([metrics['r2_score'] for metrics in target_metrics.values()])\n",
        "        \n",
        "        # Check if model meets minimum performance threshold\n",
        "        expected_r2 = model_info['expected_r2']\n",
        "        passed_threshold = avg_r2 >= expected_r2\n",
        "        \n",
        "        validation_results[model_name] = {\n",
        "            'passed': passed_threshold,\n",
        "            'avg_r2_score': avg_r2,\n",
        "            'target_metrics': target_metrics,\n",
        "            'predictions_shape': predictions.shape,\n",
        "            'sample_predictions': predictions[:3].tolist()\n",
        "        }\n",
        "        \n",
        "        print(f\"  ‚úÖ Predictions shape: {predictions.shape}\")\n",
        "        print(f\"  üìä Average R¬≤ Score: {avg_r2:.4f} (Expected: ‚â•{expected_r2:.2f})\")\n",
        "        \n",
        "        for target, metrics in target_metrics.items():\n",
        "            print(f\"    {target}: R¬≤={metrics['r2_score']:.4f}, RMSE={metrics['rmse']:.4f}\")\n",
        "            print(f\"      Prediction range: [{metrics['prediction_range'][0]:.2f}, {metrics['prediction_range'][1]:.2f}]\")\n",
        "            print(f\"      Actual range: [{metrics['actual_range'][0]:.2f}, {metrics['actual_range'][1]:.2f}]\")\n",
        "        \n",
        "        print(f\"  üìã Sample predictions:\")\n",
        "        for i, pred in enumerate(predictions[:3]):\n",
        "            print(f\"    Sample {i+1}: {pred}\")\n",
        "        \n",
        "        if passed_threshold:\n",
        "            print(f\"  üéâ {model_name} PASSED validation!\")\n",
        "            models_passed.append(model_name)\n",
        "        else:\n",
        "            print(f\"  ‚ùå {model_name} FAILED validation (R¬≤={avg_r2:.4f} < {expected_r2:.2f})\")\n",
        "            models_failed.append(model_name)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  üí• {model_name} FAILED with error: {str(e)}\")\n",
        "        models_failed.append(model_name)\n",
        "        validation_results[model_name] = {\n",
        "            'passed': False,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"üìä VALIDATION SUMMARY:\")\n",
        "print(f\"‚úÖ Models Passed: {len(models_passed)} ({', '.join(models_passed) if models_passed else 'None'})\")\n",
        "print(f\"‚ùå Models Failed: {len(models_failed)} ({', '.join(models_failed) if models_failed else 'None'})\")\n",
        "\n",
        "if not models_passed:\n",
        "    print(\"\\nüí• CRITICAL ERROR: No models passed validation!\")\n",
        "    print(\"Please check the training process and data quality.\")\n",
        "    raise ValueError(\"No models passed validation\")\n",
        "\n",
        "print(f\"\\nüéâ Validation completed! {len(models_passed)} models ready for saving.\")\n",
        "\n",
        "# Test ensemble prediction functionality\n",
        "print(\"\\nüî¨ Testing Ensemble Prediction...\")\n",
        "\n",
        "try:\n",
        "    # Create a simple ensemble prediction\n",
        "    ensemble_predictions = []\n",
        "    ensemble_weights = []\n",
        "    \n",
        "    for model_name in models_passed:\n",
        "        model_info = models_to_test[model_name]\n",
        "        model = model_info['model']\n",
        "        scaler = model_info['scaler']\n",
        "        \n",
        "        # Make prediction\n",
        "        if scaler:\n",
        "            test_features_scaled = scaler.transform(test_features)\n",
        "            pred = model.predict(test_features_scaled)\n",
        "        else:\n",
        "            pred = model.predict(test_features)\n",
        "        \n",
        "        ensemble_predictions.append(pred)\n",
        "        ensemble_weights.append(validation_results[model_name]['avg_r2_score'])\n",
        "    \n",
        "    # Weighted average ensemble\n",
        "    weights = np.array(ensemble_weights) / np.sum(ensemble_weights)\n",
        "    ensemble_pred = np.zeros_like(ensemble_predictions[0])\n",
        "    \n",
        "    for i, pred in enumerate(ensemble_predictions):\n",
        "        ensemble_pred += weights[i] * pred\n",
        "    \n",
        "    # Calculate ensemble metrics\n",
        "    ensemble_metrics = {}\n",
        "    for i, target_name in enumerate(target_cols):\n",
        "        y_true = test_targets.iloc[:, i].values\n",
        "        y_pred = ensemble_pred[:, i]\n",
        "        \n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "        mse = mean_squared_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        \n",
        "        ensemble_metrics[target_name] = {\n",
        "            'r2_score': r2,\n",
        "            'rmse': rmse\n",
        "        }\n",
        "    \n",
        "    ensemble_avg_r2 = np.mean([metrics['r2_score'] for metrics in ensemble_metrics.values()])\n",
        "    \n",
        "    print(f\"‚úÖ Ensemble prediction successful!\")\n",
        "    print(f\"üìä Ensemble R¬≤ Score: {ensemble_avg_r2:.4f}\")\n",
        "    print(f\"üìã Ensemble Metrics:\")\n",
        "    for target, metrics in ensemble_metrics.items():\n",
        "        print(f\"  {target}: R¬≤={metrics['r2_score']:.4f}, RMSE={metrics['rmse']:.4f}\")\n",
        "    \n",
        "    # Add ensemble to validation results\n",
        "    validation_results['Ensemble'] = {\n",
        "        'passed': True,\n",
        "        'avg_r2_score': ensemble_avg_r2,\n",
        "        'target_metrics': ensemble_metrics,\n",
        "        'predictions_shape': ensemble_pred.shape,\n",
        "        'sample_predictions': ensemble_pred[:3].tolist()\n",
        "    }\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Ensemble prediction failed: {str(e)}\")\n",
        "    validation_results['Ensemble'] = {\n",
        "        'passed': False,\n",
        "        'error': str(e)\n",
        "    }\n",
        "\n",
        "print(\"\\n‚úÖ Model validation and testing completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "## 6. Save Models for Module 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Saving validated models for Module 2...\n",
            "==================================================\n",
            "‚úÖ Saved XGBoost to gcFnB_pretrained_xgboost_20250824_065830.pkl\n",
            "   üìä R¬≤ Score: 0.9987\n",
            "‚úÖ Saved Random Forest to gcFnB_pretrained_random_forest_20250824_065830.pkl\n",
            "   üìä R¬≤ Score: 0.6588\n",
            "‚úÖ Saved Neural Network to gcFnB_pretrained_neural_network_20250824_065830.pkl\n",
            "   üìä R¬≤ Score: 0.3065\n",
            "\n",
            "üìä Save Summary:\n",
            "‚úÖ Successfully saved: 3 models\n",
            "‚ùå Failed to save: 0 models\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Object of type bool_ is not JSON serializable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m feature_file \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/processed/feature_columns_module2.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(feature_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 91\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Feature information saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Validation results included in feature file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: Object of type bool_ is not JSON serializable"
          ]
        }
      ],
      "source": [
        "# 7. Save Models for Module 2\n",
        "\n",
        "# Only save models that passed validation\n",
        "print(\"üíæ Saving validated models for Module 2...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create timestamp for model files\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "# Prepare model metadata for validated models only\n",
        "models_to_save = {}\n",
        "\n",
        "if 'XGBoost' in models_passed:\n",
        "    models_to_save['xgboost'] = {\n",
        "        'model': xgb_model,\n",
        "        'scaler': None,\n",
        "        'metadata': {\n",
        "            'name': 'XGBoost',\n",
        "            'type': 'tree_based',\n",
        "            'metrics': validation_results['XGBoost']['target_metrics'],\n",
        "            'avg_r2_score': validation_results['XGBoost']['avg_r2_score'],\n",
        "            'training_timestamp': timestamp,\n",
        "            'validation_passed': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "if 'Random Forest' in models_passed:\n",
        "    models_to_save['random_forest'] = {\n",
        "        'model': rf_model,\n",
        "        'scaler': None,\n",
        "        'metadata': {\n",
        "            'name': 'Random Forest',\n",
        "            'type': 'tree_based',\n",
        "            'metrics': validation_results['Random Forest']['target_metrics'],\n",
        "            'avg_r2_score': validation_results['Random Forest']['avg_r2_score'],\n",
        "            'training_timestamp': timestamp,\n",
        "            'validation_passed': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "if 'Neural Network' in models_passed:\n",
        "    models_to_save['neural_network'] = {\n",
        "        'model': nn_model,\n",
        "        'scaler': scaler_nn,\n",
        "        'metadata': {\n",
        "            'name': 'Neural Network',\n",
        "            'type': 'neural',\n",
        "            'metrics': validation_results['Neural Network']['target_metrics'],\n",
        "            'avg_r2_score': validation_results['Neural Network']['avg_r2_score'],\n",
        "            'training_timestamp': timestamp,\n",
        "            'validation_passed': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Save models\n",
        "saved_models = []\n",
        "failed_saves = []\n",
        "\n",
        "for model_key, model_data in models_to_save.items():\n",
        "    model_path = MODEL_DIR_MODULE2 / f\"gcFnB_pretrained_{model_key}_{timestamp}.pkl\"\n",
        "    \n",
        "    try:\n",
        "        joblib.dump(model_data, model_path)\n",
        "        saved_models.append(model_key)\n",
        "        print(f\"‚úÖ Saved {model_data['metadata']['name']} to {model_path.name}\")\n",
        "        print(f\"   üìä R¬≤ Score: {model_data['metadata']['avg_r2_score']:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to save {model_key}: {str(e)}\")\n",
        "        failed_saves.append(model_key)\n",
        "\n",
        "print(f\"\\nüìä Save Summary:\")\n",
        "print(f\"‚úÖ Successfully saved: {len(saved_models)} models\")\n",
        "print(f\"‚ùå Failed to save: {len(failed_saves)} models\")\n",
        "\n",
        "if not saved_models:\n",
        "    print(\"\\nüí• CRITICAL ERROR: No models were saved!\")\n",
        "    raise ValueError(\"No models were saved\")\n",
        "\n",
        "# Save feature information\n",
        "feature_info = {\n",
        "    'feature_columns': X_train.columns.tolist(),\n",
        "    'target_columns': target_cols,\n",
        "    'training_timestamp': timestamp,\n",
        "    'validation_results': validation_results,\n",
        "    'models_passed': models_passed,\n",
        "    'models_failed': models_failed\n",
        "}\n",
        "\n",
        "feature_file = Path(\"../data/processed/feature_columns_module2.json\")\n",
        "with open(feature_file, 'w') as f:\n",
        "    json.dump(feature_info, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Feature information saved to {feature_file.name}\")\n",
        "print(f\"‚úÖ Validation results included in feature file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 7. Training Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üéâ MODULE 2 TRAINING & VALIDATION COMPLETE!\n",
            "============================================================\n",
            "\n",
            "üèÜ Final Model Rankings (Validated):\n",
            "         Model  R¬≤ Score                  Type\n",
            "       XGBoost  0.998682          XGBRegressor\n",
            " Random Forest  0.658823 RandomForestRegressor\n",
            "Neural Network  0.306534          MLPRegressor\n",
            "\n",
            "üìä Validation Summary:\n",
            "‚úÖ Models Passed: 3 (XGBoost, Random Forest, Neural Network)\n",
            "‚ùå Models Failed: 0 (None)\n",
            "üíæ Models Saved: 3 (xgboost, random_forest, neural_network)\n",
            "üèÜ Best Model: XGBoost (R¬≤ = 0.9987)\n",
            "üìÅ Models saved in: D:\\NoSQL\\Honeywell\\data\\model_module2\n",
            "‚è∞ Training timestamp: 20250824_065830\n",
            "\n",
            "‚úÖ Ready for Module 2 Integration!\n",
            "\n",
            "üìã Next Steps:\n",
            "  1. Start the web application: python app/app_v2.py\n",
            "  2. Access Module 2 for instant predictions\n",
            "  3. Upload process data and get predictions in < 1 second\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "#8. Training Summary\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üéâ MODULE 2 TRAINING & VALIDATION COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create comparison for validated models only\n",
        "validated_models = []\n",
        "for model_name in models_passed:\n",
        "    validated_models.append({\n",
        "        'Model': model_name,\n",
        "        'R¬≤ Score': validation_results[model_name]['avg_r2_score'],\n",
        "        'Type': models_to_test[model_name]['model'].__class__.__name__\n",
        "    })\n",
        "\n",
        "if validated_models:\n",
        "    model_comparison = pd.DataFrame(validated_models).sort_values('R¬≤ Score', ascending=False)\n",
        "    print(\"\\nüèÜ Final Model Rankings (Validated):\")\n",
        "    print(model_comparison.to_string(index=False))\n",
        "\n",
        "print(f\"\\nüìä Validation Summary:\")\n",
        "print(f\"‚úÖ Models Passed: {len(models_passed)} ({', '.join(models_passed) if models_passed else 'None'})\")\n",
        "print(f\"‚ùå Models Failed: {len(models_failed)} ({', '.join(models_failed) if models_failed else 'None'})\")\n",
        "print(f\"üíæ Models Saved: {len(saved_models)} ({', '.join(saved_models) if saved_models else 'None'})\")\n",
        "\n",
        "if models_passed:\n",
        "    best_model = max(models_passed, key=lambda x: validation_results[x]['avg_r2_score'])\n",
        "    best_score = validation_results[best_model]['avg_r2_score']\n",
        "    print(f\"üèÜ Best Model: {best_model} (R¬≤ = {best_score:.4f})\")\n",
        "\n",
        "print(f\"üìÅ Models saved in: {MODEL_DIR_MODULE2}\")\n",
        "print(f\"‚è∞ Training timestamp: {timestamp}\")\n",
        "\n",
        "print(\"\\n‚úÖ Ready for Module 2 Integration!\")\n",
        "print(\"\\nüìã Next Steps:\")\n",
        "print(\"  1. Start the web application: python app/app_v2.py\")\n",
        "print(\"  2. Access Module 2 for instant predictions\")\n",
        "print(\"  3. Upload process data and get predictions in < 1 second\")\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gcvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
