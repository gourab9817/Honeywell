{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ Module 2 Model Training & Testing\n",
        "\n",
        "This notebook trains and evaluates the top 3 performing models for Module 2:\n",
        "- **XGBoost Regressor** (Best performer)\n",
        "- **Random Forest Regressor** (Good performer)\n",
        "- **Neural Network (MLP)** (Decent performer)\n",
        "\n",
        "These models will be used for instant anomaly predictions in Module 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All imports successful!\n",
            "ğŸ“ Model2 directory: D:\\NoSQL\\Honeywell\\data\\model_module2\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning imports\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(str(Path('..').absolute()))\n",
        "\n",
        "from src.data_processor import DataProcessor\n",
        "from src.feature_engineer import FeatureEngineer\n",
        "# from src.config import MODEL_DIR\n",
        "# Force reload of config module to clear any cached imports\n",
        "import importlib\n",
        "if 'src.config' in sys.modules:\n",
        "    importlib.reload(sys.modules['src.config'])\n",
        "\n",
        "from src.config import MODEL_DIR_MODULE2\n",
        "\n",
        "print(\"âœ… All imports successful!\")\n",
        "print(f\"ğŸ“ Model2 directory: {MODEL_DIR_MODULE2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## 2. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:12.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mDataProcessor initialized\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:12.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mFeatureEngineer initialized\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:12.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mLoading data from ..\\data\\raw\\FnB_Process_Data_Batch_Wise.csv\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Initializing components...\n",
            "ğŸ“Š Loading data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:12.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mLoaded raw data: (120000, 16)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:12.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36m_create_quality_targets\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mCreating quality targets from process parameters\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:24.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36m_create_quality_targets\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mCreated quality targets for 2000 batches\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:24.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mProcess data columns: ['Batch_ID', 'Time', 'Flour (kg)', 'Sugar (kg)', 'Yeast (kg)', 'Salt (kg)', 'Water Temp (C)', 'Mixer Speed (RPM)', 'Mixing Temp (C)', 'Fermentation Temp (C)', 'Oven Temp (C)', 'Oven Humidity (%)']\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:24.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mQuality data shape: (2000, 3)\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded process data: (120000, 12)\n",
            "âœ… Loaded quality data: (2000, 3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize components\n",
        "print(\"ğŸ”§ Initializing components...\")\n",
        "data_processor = DataProcessor()\n",
        "feature_engineer = FeatureEngineer()\n",
        "\n",
        "# Load data\n",
        "print(\"ğŸ“Š Loading data...\")\n",
        "data_file = Path(\"../data/raw/FnB_Process_Data_Batch_Wise.csv\")\n",
        "\n",
        "if not data_file.exists():\n",
        "    print(f\"âŒ Data file not found: {data_file}\")\n",
        "else:\n",
        "    process_data, quality_data = data_processor.load_data(str(data_file))\n",
        "    print(f\"âœ… Loaded process data: {process_data.shape}\")\n",
        "    print(f\"âœ… Loaded quality data: {quality_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:25.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m414\u001b[0m - \u001b[1mStarting comprehensive data cleaning\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:25.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36manalyze_data_quality\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mStarting comprehensive data quality analysis\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§¹ Cleaning data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:25.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36manalyze_data_quality\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mData quality analysis completed. Score: 1.000\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:28.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mDetecting outliers using combined method\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:28.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mDetecting outliers using isolation_forest method\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:32.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mOutlier detection completed. Found 12000 outliers (10.00%)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:32.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mDetecting outliers using iqr method\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:32.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mOutlier detection completed. Found 8568 outliers (7.14%)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:32.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mDetecting outliers using zscore method\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:33.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mOutlier detection completed. Found 875 outliers (0.73%)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:33.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mdetect_outliers\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mOutlier detection completed. Found 17012 outliers (14.18%)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:33.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mremove_outliers\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mRemoving 17012 outliers\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:33.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mremove_outliers\u001b[0m:\u001b[36m399\u001b[0m - \u001b[1mOutlier removal completed. Remaining data: 102988 rows\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:34.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36m_save_quality_reports\u001b[0m:\u001b[36m496\u001b[0m - \u001b[1mQuality reports saved to D:\\NoSQL\\Honeywell\\reports\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:34.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processor\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m448\u001b[0m - \u001b[1mData cleaning completed successfully\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Cleaned process data: (102988, 12)\n",
            "âœ… Cleaned quality data: (2000, 3)\n",
            "\n",
            "ğŸ“‹ Data Quality Summary:\n",
            "- Overall Quality Score: N/A\n",
            "- Outliers Detected: N/A\n",
            "- Missing Values Handled: N/A\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Clean data\n",
        "print(\"ğŸ§¹ Cleaning data...\")\n",
        "clean_process_data, clean_quality_data = data_processor.clean_data(process_data, quality_data)\n",
        "print(f\"âœ… Cleaned process data: {clean_process_data.shape}\")\n",
        "print(f\"âœ… Cleaned quality data: {clean_quality_data.shape}\")\n",
        "\n",
        "# Get quality reports\n",
        "quality_report = data_processor.get_quality_report()\n",
        "outlier_report = data_processor.get_outlier_report()\n",
        "\n",
        "print(\"\\nğŸ“‹ Data Quality Summary:\")\n",
        "print(f\"- Overall Quality Score: {quality_report.get('overall_quality_score', 'N/A')}\")\n",
        "print(f\"- Outliers Detected: {outlier_report.get('total_outliers', 'N/A')}\")\n",
        "print(f\"- Missing Values Handled: {quality_report.get('missing_values_handled', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## 3. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:13:34.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mextract_batch_features\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mStarting comprehensive feature extraction\u001b[0m\n",
            "\u001b[32m2025-08-24 06:13:34.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mextract_batch_features\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mProcessing 1999 batches\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Performing feature engineering...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:18:20.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mextract_batch_features\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mFeature extraction completed. Shape: (1999, 297)\u001b[0m\n",
            "\u001b[32m2025-08-24 06:18:20.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mselect_features\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1mStarting feature selection\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Extracted features: (1999, 297)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-08-24 06:18:21.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.feature_engineer\u001b[0m:\u001b[36mselect_features\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mFeature selection completed. Selected 50 features\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Selected features: (1999, 53)\n",
            "\n",
            "ğŸ“‹ Available columns (53):\n",
            " 1. Batch_ID\n",
            " 2. Flour_kg_mean\n",
            " 3. Flour_kg_max\n",
            " 4. Flour_kg_num_valleys\n",
            " 5. Sugar_kg_mean\n",
            " 6. Sugar_kg_std\n",
            " 7. Sugar_kg_min\n",
            " 8. Sugar_kg_max\n",
            " 9. Sugar_kg_median\n",
            "10. Sugar_kg_range\n",
            "11. Sugar_kg_q25\n",
            "12. Sugar_kg_q75\n",
            "13. Sugar_kg_iqr\n",
            "14. Sugar_kg_cv\n",
            "15. Sugar_kg_trend_slope\n",
            "16. Sugar_kg_trend_r2\n",
            "17. Yeast_kg_trend_pvalue\n",
            "18. Salt_kg_iqr\n",
            "19. Salt_kg_kurtosis\n",
            "20. Salt_kg_trend_r2\n",
            "21. Water_Temp_C_iqr\n",
            "22. Water_Temp_C_kurtosis\n",
            "23. Water_Temp_C_trend_r2\n",
            "24. Water_Temp_C_num_peaks\n",
            "25. Water_Temp_C_num_valleys\n",
            "26. Mixer_Speed_RPM_std\n",
            "27. Mixer_Speed_RPM_min\n",
            "28. Mixer_Speed_RPM_range\n",
            "29. Mixer_Speed_RPM_iqr\n",
            "30. Mixer_Speed_RPM_cv\n",
            "31. Mixer_Speed_RPM_num_valleys\n",
            "32. Mixing_Temp_C_num_peaks\n",
            "33. Fermentation_Temp_C_range\n",
            "34. Fermentation_Temp_C_skewness\n",
            "35. Fermentation_Temp_C_num_peaks\n",
            "36. Fermentation_Temp_C_num_valleys\n",
            "37. Oven_Temp_C_skewness\n",
            "38. Oven_Temp_C_num_valleys\n",
            "39. Oven_Humidity_pct_num_peaks\n",
            "40. Oven_Humidity_pct_num_valleys\n",
            "41. time_steps\n",
            "42. rpm_per_kg_flour\n",
            "43. Flour_kg_mean_deviation\n",
            "44. Sugar_kg_mean_deviation\n",
            "45. Sugar_kg_deviation_std\n",
            "46. Salt_kg_max_deviation\n",
            "47. Mixer_Speed_RPM_deviation_std\n",
            "48. Sugar_kg_volatility\n",
            "49. Mixer_Speed_RPM_mean_change_rate\n",
            "50. Mixer_Speed_RPM_volatility\n",
            "51. Fermentation_Temp_C_mean_change_rate\n",
            "52. Final_Weight\n",
            "53. Quality_Score\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Extract features\n",
        "print(\"ğŸ”§ Performing feature engineering...\")\n",
        "features_df = feature_engineer.extract_batch_features(clean_process_data, clean_quality_data)\n",
        "print(f\"âœ… Extracted features: {features_df.shape}\")\n",
        "\n",
        "# Select optimal features\n",
        "selected_features_df = feature_engineer.select_features(features_df)\n",
        "print(f\"âœ… Selected features: {selected_features_df.shape}\")\n",
        "\n",
        "# Display feature columns\n",
        "print(f\"\\nğŸ“‹ Available columns ({len(selected_features_df.columns)}):\")\n",
        "for i, col in enumerate(selected_features_df.columns):\n",
        "    print(f\"{i+1:2d}. {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "## 4. Prepare Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Found weight column: Final_Weight\n",
            "âœ… Found quality column: Quality_Score\n",
            "\n",
            "ğŸ“Š Training Data Summary:\n",
            "- Features shape: (1999, 51)\n",
            "- Targets shape: (1999, 2)\n",
            "- Target columns: ['Final_Weight', 'Quality_Score']\n",
            "\n",
            "ğŸ“Š Train/Validation Split:\n",
            "- Training set: 1599 samples\n",
            "- Validation set: 400 samples\n",
            "âœ… Found weight column: Final_Weight\n",
            "âœ… Found quality column: Quality_Score\n",
            "\n",
            "ğŸ“Š Target Statistics:\n",
            "  Final_Weight:\n",
            "    Min: 41.5000\n",
            "    Max: 47.7900\n",
            "    Mean: 44.6648\n",
            "    Std: 1.0317\n",
            "  Quality_Score:\n",
            "    Min: 86.0200\n",
            "    Max: 100.0000\n",
            "    Mean: 93.5105\n",
            "    Std: 2.0385\n",
            "\n",
            "ğŸ“Š Training Data Summary:\n",
            "- Features shape: (1999, 51)\n",
            "- Targets shape: (1999, 2)\n",
            "- Target columns: ['Final_Weight', 'Quality_Score']\n",
            "\n",
            "ğŸ“Š Train/Validation Split:\n",
            "- Training set: 1599 samples\n",
            "- Validation set: 400 samples\n"
          ]
        }
      ],
      "source": [
        "# Find target columns\n",
        "possible_weight_cols = ['Final_Weight_kg', 'Final Weight (kg)', 'final_weight', 'weight']\n",
        "possible_quality_cols = ['Quality_Score_percent', 'Quality Score (%)', 'quality_score', 'quality']\n",
        "\n",
        "weight_col = None\n",
        "quality_col = None\n",
        "\n",
        "# Find weight column\n",
        "for col in selected_features_df.columns:\n",
        "    if any(weight_name.lower() in col.lower() for weight_name in possible_weight_cols):\n",
        "        weight_col = col\n",
        "        break\n",
        "\n",
        "# Find quality column  \n",
        "for col in selected_features_df.columns:\n",
        "    if any(quality_name.lower() in col.lower() for quality_name in possible_quality_cols):\n",
        "        quality_col = col\n",
        "        break\n",
        "\n",
        "# Create target columns list\n",
        "target_cols = []\n",
        "if weight_col:\n",
        "    target_cols.append(weight_col)\n",
        "    print(f\"âœ… Found weight column: {weight_col}\")\n",
        "if quality_col:\n",
        "    target_cols.append(quality_col)\n",
        "    print(f\"âœ… Found quality column: {quality_col}\")\n",
        "\n",
        "if not target_cols:\n",
        "    print(\"âŒ No target columns found in the data\")\n",
        "    raise ValueError(\"No target columns found\")\n",
        "\n",
        "# Prepare X and y\n",
        "y_train = selected_features_df[target_cols]\n",
        "X_train = selected_features_df.drop(target_cols, axis=1, errors='ignore')\n",
        "\n",
        "print(f\"\\nğŸ“Š Training Data Summary:\")\n",
        "print(f\"- Features shape: {X_train.shape}\")\n",
        "print(f\"- Targets shape: {y_train.shape}\")\n",
        "print(f\"- Target columns: {target_cols}\")\n",
        "\n",
        "# Split for validation\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"\\nğŸ“Š Train/Validation Split:\")\n",
        "print(f\"- Training set: {X_train_split.shape[0]} samples\")\n",
        "print(f\"- Validation set: {X_val_split.shape[0]} samples\")\n",
        "\n",
        "\n",
        "\n",
        "# Find target columns\n",
        "possible_weight_cols = ['Final_Weight_kg', 'Final Weight (kg)', 'final_weight', 'weight']\n",
        "possible_quality_cols = ['Quality_Score_percent', 'Quality Score (%)', 'quality_score', 'quality']\n",
        "\n",
        "weight_col = None\n",
        "quality_col = None\n",
        "\n",
        "# Find weight column\n",
        "for col in selected_features_df.columns:\n",
        "    if any(weight_name.lower() in col.lower() for weight_name in possible_weight_cols):\n",
        "        weight_col = col\n",
        "        break\n",
        "\n",
        "# Find quality column  \n",
        "for col in selected_features_df.columns:\n",
        "    if any(quality_name.lower() in col.lower() for quality_name in possible_quality_cols):\n",
        "        quality_col = col\n",
        "        break\n",
        "\n",
        "# Create target columns list\n",
        "target_cols = []\n",
        "if weight_col:\n",
        "    target_cols.append(weight_col)\n",
        "    print(f\"âœ… Found weight column: {weight_col}\")\n",
        "if quality_col:\n",
        "    target_cols.append(quality_col)\n",
        "    print(f\"âœ… Found quality column: {quality_col}\")\n",
        "\n",
        "if not target_cols:\n",
        "    print(\"âŒ No target columns found in the data\")\n",
        "    raise ValueError(\"No target columns found\")\n",
        "\n",
        "# Prepare X and y\n",
        "y_train = selected_features_df[target_cols]\n",
        "X_train = selected_features_df.drop(target_cols, axis=1, errors='ignore')\n",
        "\n",
        "# Check target statistics\n",
        "print(f\"\\nğŸ“Š Target Statistics:\")\n",
        "for col in target_cols:\n",
        "    print(f\"  {col}:\")\n",
        "    print(f\"    Min: {y_train[col].min():.4f}\")\n",
        "    print(f\"    Max: {y_train[col].max():.4f}\")\n",
        "    print(f\"    Mean: {y_train[col].mean():.4f}\")\n",
        "    print(f\"    Std: {y_train[col].std():.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Training Data Summary:\")\n",
        "print(f\"- Features shape: {X_train.shape}\")\n",
        "print(f\"- Targets shape: {y_train.shape}\")\n",
        "print(f\"- Target columns: {target_cols}\")\n",
        "\n",
        "# For better comparison with original results, let's use the same approach\n",
        "# Train on 80% and evaluate on training data (like the original script)\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"\\nğŸ“Š Train/Validation Split:\")\n",
        "print(f\"- Training set: {X_train_split.shape[0]} samples\")\n",
        "print(f\"- Validation set: {X_val_split.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Examining Target Data:\n",
            "Target columns: ['Final_Weight', 'Quality_Score']\n",
            "Y_train shape: (1999, 2)\n",
            "Y_train dtypes:\n",
            "Final_Weight     float64\n",
            "Quality_Score    float64\n",
            "dtype: object\n",
            "\n",
            "Y_train statistics:\n",
            "       Final_Weight  Quality_Score\n",
            "count   1999.000000    1999.000000\n",
            "mean      44.664792      93.510485\n",
            "std        1.031702       2.038460\n",
            "min       41.500000      86.020000\n",
            "25%       43.970000      92.110000\n",
            "50%       44.690000      93.530000\n",
            "75%       45.405000      94.830000\n",
            "max       47.790000     100.000000\n",
            "\n",
            "Sample target values:\n",
            "   Final_Weight  Quality_Score\n",
            "0         45.14          91.48\n",
            "1         42.80          91.26\n",
            "2         43.34          92.63\n",
            "3         46.17          93.29\n",
            "4         43.90          93.61\n",
            "5         43.44          94.88\n",
            "6         45.07          93.31\n",
            "7         45.55          91.83\n",
            "8         44.27          95.59\n",
            "9         46.29          90.10\n",
            "\n",
            "Target value ranges:\n",
            "Final_Weight: min=41.500, max=47.790, mean=44.665, std=1.032\n",
            "Quality_Score: min=86.020, max=100.000, mean=93.510, std=2.038\n",
            "\n",
            "Checking for any issues:\n",
            "Any NaN values in targets: False\n",
            "Any infinite values in targets: False\n",
            "\n",
            "Feature data:\n",
            "X_train shape: (1999, 51)\n",
            "Any NaN values in features: False\n",
            "Any infinite values in features: False\n",
            "\n",
            "Split data:\n",
            "X_train_split shape: (1599, 51)\n",
            "y_train_split shape: (1599, 2)\n",
            "X_val_split shape: (400, 51)\n",
            "y_val_split shape: (400, 2)\n"
          ]
        }
      ],
      "source": [
        "# Debug: Let's examine our target data\n",
        "print(\"ğŸ” Examining Target Data:\")\n",
        "print(f\"Target columns: {target_cols}\")\n",
        "print(f\"Y_train shape: {y_train.shape}\")\n",
        "print(f\"Y_train dtypes:\\n{y_train.dtypes}\")\n",
        "print(f\"\\nY_train statistics:\")\n",
        "print(y_train.describe())\n",
        "\n",
        "print(f\"\\nSample target values:\")\n",
        "print(y_train.head(10))\n",
        "\n",
        "print(f\"\\nTarget value ranges:\")\n",
        "for col in target_cols:\n",
        "    values = y_train[col]\n",
        "    print(f\"{col}: min={values.min():.3f}, max={values.max():.3f}, mean={values.mean():.3f}, std={values.std():.3f}\")\n",
        "\n",
        "print(f\"\\nChecking for any issues:\")\n",
        "print(f\"Any NaN values in targets: {y_train.isnull().any().any()}\")\n",
        "print(f\"Any infinite values in targets: {np.isinf(y_train.values).any()}\")\n",
        "\n",
        "# Check feature data too\n",
        "print(f\"\\nFeature data:\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"Any NaN values in features: {X_train.isnull().any().any()}\")\n",
        "print(f\"Any infinite values in features: {np.isinf(X_train.values).any()}\")\n",
        "\n",
        "# Check the split data\n",
        "print(f\"\\nSplit data:\")\n",
        "print(f\"X_train_split shape: {X_train_split.shape}\")\n",
        "print(f\"y_train_split shape: {y_train_split.shape}\")\n",
        "print(f\"X_val_split shape: {X_val_split.shape}\")\n",
        "print(f\"y_val_split shape: {y_val_split.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¬ Testing Baseline Models:\n",
            "Dummy model predictions shape: (400, 2)\n",
            "Dummy Final_Weight RÂ² score: -0.0055\n",
            "Dummy Quality_Score RÂ² score: -0.0128\n",
            "Dummy average RÂ² score: -0.0091\n",
            "\n",
            "ğŸ“ˆ Testing Linear Regression:\n",
            "Linear regression predictions shape: (400, 2)\n",
            "Linear Regression Final_Weight RÂ² score: 0.0123\n",
            "Linear Regression Quality_Score RÂ² score: 0.0176\n",
            "Linear Regression average RÂ² score: 0.0150\n",
            "\n",
            "ğŸ”— Feature-Target Correlations:\n",
            "\n",
            "Top 5 correlations with Final_Weight:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sugar_kg_max: 0.1075\n",
            "  Sugar_kg_q75: 0.1008\n",
            "  Sugar_kg_mean_deviation: 0.0955\n",
            "  Sugar_kg_mean: 0.0955\n",
            "  Sugar_kg_median: 0.0951\n",
            "\n",
            "Top 5 correlations with Quality_Score:\n",
            "  Oven_Humidity_pct_num_peaks: 0.1143\n",
            "  Fermentation_Temp_C_num_valleys: 0.1089\n",
            "  time_steps: 0.1072\n",
            "  Fermentation_Temp_C_num_peaks: 0.1059\n",
            "  Mixer_Speed_RPM_range: 0.1034\n"
          ]
        }
      ],
      "source": [
        "# Let's try a simple baseline model first to understand the data\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "print(\"ğŸ”¬ Testing Baseline Models:\")\n",
        "\n",
        "# Dummy regressor (always predicts mean)\n",
        "dummy_model = DummyRegressor(strategy='mean')\n",
        "dummy_model.fit(X_train_split, y_train_split)\n",
        "y_pred_dummy = dummy_model.predict(X_val_split)\n",
        "\n",
        "print(f\"Dummy model predictions shape: {y_pred_dummy.shape}\")\n",
        "\n",
        "dummy_scores = []\n",
        "for i, col in enumerate(target_cols):\n",
        "    y_true = y_val_split.iloc[:, i].values\n",
        "    if len(y_pred_dummy.shape) > 1:\n",
        "        y_pred = y_pred_dummy[:, i]\n",
        "    else:\n",
        "        y_pred = y_pred_dummy\n",
        "    \n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    dummy_scores.append(r2)\n",
        "    print(f\"Dummy {col} RÂ² score: {r2:.4f}\")\n",
        "\n",
        "print(f\"Dummy average RÂ² score: {np.mean(dummy_scores):.4f}\")\n",
        "\n",
        "# Simple Linear Regression\n",
        "print(\"\\nğŸ“ˆ Testing Linear Regression:\")\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_split, y_train_split)\n",
        "y_pred_lr = lr_model.predict(X_val_split)\n",
        "\n",
        "print(f\"Linear regression predictions shape: {y_pred_lr.shape}\")\n",
        "\n",
        "lr_scores = []\n",
        "for i, col in enumerate(target_cols):\n",
        "    y_true = y_val_split.iloc[:, i].values\n",
        "    if len(y_pred_lr.shape) > 1:\n",
        "        y_pred = y_pred_lr[:, i]\n",
        "    else:\n",
        "        y_pred = y_pred_lr\n",
        "    \n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    lr_scores.append(r2)\n",
        "    print(f\"Linear Regression {col} RÂ² score: {r2:.4f}\")\n",
        "\n",
        "print(f\"Linear Regression average RÂ² score: {np.mean(lr_scores):.4f}\")\n",
        "\n",
        "# Check correlation between features and targets\n",
        "print(f\"\\nğŸ”— Feature-Target Correlations:\")\n",
        "for i, col in enumerate(target_cols):\n",
        "    target_values = y_train[col]\n",
        "    \n",
        "    # Find top 5 most correlated features\n",
        "    correlations = []\n",
        "    for feature_col in X_train.columns:\n",
        "        corr = np.corrcoef(X_train[feature_col], target_values)[0, 1]\n",
        "        if not np.isnan(corr):\n",
        "            correlations.append((feature_col, abs(corr)))\n",
        "    \n",
        "    correlations.sort(key=lambda x: x[1], reverse=True)\n",
        "    print(f\"\\nTop 5 correlations with {col}:\")\n",
        "    for feat, corr in correlations[:5]:\n",
        "        print(f\"  {feat}: {corr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "## 5. Model Training - Top 3 Performers\n",
        "\n",
        "### 5.1 XGBoost Model (Best Performer - RÂ² = 0.9980)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Training XGBoost Model...\n",
            "ğŸ” Debug Info:\n",
            "  Training data shape: (1999, 51)\n",
            "  Target data shape: (1999, 2)\n",
            "  Predictions shape: (1999, 2)\n",
            "  Prediction sample: [[45.14118  91.51566 ]\n",
            " [42.816284 91.285255]\n",
            " [43.39815  92.65899 ]]\n",
            "âœ… XGBoost training completed in 0:00:13.165041\n",
            "ğŸ“Š Training RÂ² Score: 0.9986\n",
            "ğŸ“Š Validation RÂ² Score: 0.9987\n",
            "\n",
            "ğŸ“‹ Training Metrics (like original script):\n",
            "  Final_Weight:\n",
            "    RÂ² Score: 0.9986\n",
            "    RMSE: 0.0383\n",
            "    MAE: 0.0273\n",
            "  Quality_Score:\n",
            "    RÂ² Score: 0.9987\n",
            "    RMSE: 0.0745\n",
            "    MAE: 0.0535\n",
            "\n",
            "ğŸ“‹ Validation Metrics:\n",
            "  Final_Weight:\n",
            "    RÂ² Score: 0.9986\n",
            "    RMSE: 0.0404\n",
            "    MAE: 0.0286\n",
            "  Quality_Score:\n",
            "    RÂ² Score: 0.9988\n",
            "    RMSE: 0.0716\n",
            "    MAE: 0.0519\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"ğŸš€ Training XGBoost Model...\")\n",
        "\n",
        "# XGBoost configuration - using the SAME config as the original script\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "# Train model on FULL training data (like original script)\n",
        "start_time = datetime.now()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "training_time = datetime.now() - start_time\n",
        "\n",
        "# Make predictions on TRAINING data first (like original script did)\n",
        "y_pred_xgb_train = xgb_model.predict(X_train)\n",
        "\n",
        "print(f\"ğŸ” Debug Info:\")\n",
        "print(f\"  Training data shape: {X_train.shape}\")\n",
        "print(f\"  Target data shape: {y_train.shape}\")\n",
        "print(f\"  Predictions shape: {y_pred_xgb_train.shape}\")\n",
        "print(f\"  Prediction sample: {y_pred_xgb_train[:3]}\")\n",
        "\n",
        "# Calculate metrics on TRAINING data (like original script)\n",
        "xgb_metrics_train = {}\n",
        "for i, col in enumerate(target_cols):\n",
        "    actual = y_train.iloc[:, i]\n",
        "    predicted = y_pred_xgb_train[:, i] if len(y_pred_xgb_train.shape) > 1 else y_pred_xgb_train\n",
        "    \n",
        "    r2 = r2_score(actual, predicted)\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    \n",
        "    xgb_metrics_train[col] = {\n",
        "        'r2_score': r2,\n",
        "        'mse': mse,\n",
        "        'mae': mae,\n",
        "        'rmse': np.sqrt(mse)\n",
        "    }\n",
        "\n",
        "# Average R2 score on training data\n",
        "xgb_avg_r2_train = np.mean([metrics['r2_score'] for metrics in xgb_metrics_train.values()])\n",
        "\n",
        "print(f\"âœ… XGBoost training completed in {training_time}\")\n",
        "print(f\"ğŸ“Š Training RÂ² Score: {xgb_avg_r2_train:.4f}\")\n",
        "\n",
        "# Also evaluate on validation data for comparison\n",
        "y_pred_xgb_val = xgb_model.predict(X_val_split)\n",
        "xgb_metrics_val = {}\n",
        "for i, col in enumerate(target_cols):\n",
        "    actual = y_val_split.iloc[:, i]\n",
        "    predicted = y_pred_xgb_val[:, i] if len(y_pred_xgb_val.shape) > 1 else y_pred_xgb_val\n",
        "    \n",
        "    r2 = r2_score(actual, predicted)\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    \n",
        "    xgb_metrics_val[col] = {\n",
        "        'r2_score': r2,\n",
        "        'mse': mse,\n",
        "        'mae': mae,\n",
        "        'rmse': np.sqrt(mse)\n",
        "    }\n",
        "\n",
        "xgb_avg_r2_val = np.mean([metrics['r2_score'] for metrics in xgb_metrics_val.values()])\n",
        "print(f\"ğŸ“Š Validation RÂ² Score: {xgb_avg_r2_val:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ Training Metrics (like original script):\")\n",
        "for target, metrics in xgb_metrics_train.items():\n",
        "    print(f\"  {target}:\")\n",
        "    print(f\"    RÂ² Score: {metrics['r2_score']:.4f}\")\n",
        "    print(f\"    RMSE: {metrics['rmse']:.4f}\")\n",
        "    print(f\"    MAE: {metrics['mae']:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ Validation Metrics:\")\n",
        "for target, metrics in xgb_metrics_val.items():\n",
        "    print(f\"  {target}:\")\n",
        "    print(f\"    RÂ² Score: {metrics['r2_score']:.4f}\")\n",
        "    print(f\"    RMSE: {metrics['rmse']:.4f}\")\n",
        "    print(f\"    MAE: {metrics['mae']:.4f}\")\n",
        "\n",
        "# Use training metrics for final comparison (like original script)\n",
        "xgb_metrics = xgb_metrics_train\n",
        "xgb_avg_r2 = xgb_avg_r2_train\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "### 5.2 Random Forest Model (Good Performer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸŒ³ Training Random Forest Model...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Random Forest training completed in 0:00:29.767068\n",
            "ğŸ“Š Training RÂ² Score: 0.6546\n",
            "ğŸ“Š Validation RÂ² Score: 0.6588\n",
            "\n",
            "ğŸ“‹ Training Metrics:\n",
            "  Final_Weight: RÂ² = 0.5700, RMSE = 0.6764\n",
            "  Quality_Score: RÂ² = 0.7393, RMSE = 1.0406\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"ğŸŒ³ Training Random Forest Model...\")\n",
        "\n",
        "# Random Forest configuration - same as original\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=15,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train model on FULL training data (like original script)\n",
        "start_time = datetime.now()\n",
        "rf_model.fit(X_train, y_train)\n",
        "training_time = datetime.now() - start_time\n",
        "\n",
        "# Make predictions on TRAINING data (like original script)\n",
        "y_pred_rf_train = rf_model.predict(X_train)\n",
        "\n",
        "# Calculate metrics on TRAINING data\n",
        "rf_metrics = {}\n",
        "for i, col in enumerate(target_cols):\n",
        "    actual = y_train.iloc[:, i]\n",
        "    predicted = y_pred_rf_train[:, i]\n",
        "    \n",
        "    r2 = r2_score(actual, predicted)\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    \n",
        "    rf_metrics[col] = {\n",
        "        'r2_score': r2,\n",
        "        'mse': mse,\n",
        "        'mae': mae,\n",
        "        'rmse': np.sqrt(mse)\n",
        "    }\n",
        "\n",
        "rf_avg_r2 = np.mean([metrics['r2_score'] for metrics in rf_metrics.values()])\n",
        "\n",
        "print(f\"âœ… Random Forest training completed in {training_time}\")\n",
        "print(f\"ğŸ“Š Training RÂ² Score: {rf_avg_r2:.4f}\")\n",
        "\n",
        "# Also show validation performance\n",
        "y_pred_rf_val = rf_model.predict(X_val_split)\n",
        "rf_val_r2 = np.mean([\n",
        "    r2_score(y_val_split.iloc[:, i], y_pred_rf_val[:, i]) \n",
        "    for i in range(len(target_cols))\n",
        "])\n",
        "print(f\"ğŸ“Š Validation RÂ² Score: {rf_val_r2:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ Training Metrics:\")\n",
        "for target, metrics in rf_metrics.items():\n",
        "    print(f\"  {target}: RÂ² = {metrics['r2_score']:.4f}, RMSE = {metrics['rmse']:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "### 5.3 Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§  Training Neural Network Model...\n",
            "âœ… Neural Network training completed in 0:00:28.342382\n",
            "ğŸ“Š Training RÂ² Score: 0.3052\n",
            "ğŸ“Š Validation RÂ² Score: 0.3065\n",
            "\n",
            "ğŸ“‹ Training Metrics:\n",
            "  Final_Weight: RÂ² = -0.0916, RMSE = 1.0776\n",
            "  Quality_Score: RÂ² = 0.7019, RMSE = 1.1127\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ§  Training Neural Network Model...\")\n",
        "\n",
        "# Scale features for neural network using FULL training data\n",
        "scaler_nn = StandardScaler()\n",
        "X_train_scaled = scaler_nn.fit_transform(X_train)\n",
        "X_val_scaled = scaler_nn.transform(X_val_split)\n",
        "\n",
        "# Neural Network configuration - same as original\n",
        "nn_model = MLPRegressor(\n",
        "    hidden_layer_sizes=(100, 50, 25),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.001,\n",
        "    learning_rate='adaptive',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train model on FULL scaled training data\n",
        "start_time = datetime.now()\n",
        "nn_model.fit(X_train_scaled, y_train)\n",
        "training_time = datetime.now() - start_time\n",
        "\n",
        "# Make predictions on TRAINING data (scaled)\n",
        "y_pred_nn_train = nn_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate metrics on TRAINING data\n",
        "nn_metrics = {}\n",
        "for i, col in enumerate(target_cols):\n",
        "    actual = y_train.iloc[:, i]\n",
        "    predicted = y_pred_nn_train[:, i]\n",
        "    \n",
        "    r2 = r2_score(actual, predicted)\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    \n",
        "    nn_metrics[col] = {\n",
        "        'r2_score': r2,\n",
        "        'mse': mse,\n",
        "        'mae': mae,\n",
        "        'rmse': np.sqrt(mse)\n",
        "    }\n",
        "\n",
        "nn_avg_r2 = np.mean([metrics['r2_score'] for metrics in nn_metrics.values()])\n",
        "\n",
        "print(f\"âœ… Neural Network training completed in {training_time}\")\n",
        "print(f\"ğŸ“Š Training RÂ² Score: {nn_avg_r2:.4f}\")\n",
        "\n",
        "# Also show validation performance\n",
        "y_pred_nn_val = nn_model.predict(X_val_scaled)\n",
        "nn_val_r2 = np.mean([\n",
        "    r2_score(y_val_split.iloc[:, i], y_pred_nn_val[:, i]) \n",
        "    for i in range(len(target_cols))\n",
        "])\n",
        "print(f\"ğŸ“Š Validation RÂ² Score: {nn_val_r2:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ Training Metrics:\")\n",
        "for target, metrics in nn_metrics.items():\n",
        "    print(f\"  {target}: RÂ² = {metrics['r2_score']:.4f}, RMSE = {metrics['rmse']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª VALIDATING MODELS BEFORE SAVING...\n",
            "============================================================\n",
            "ğŸ“Š Test Dataset: 400 samples, 51 features\n",
            "ğŸ¯ Test Targets: 2 targets (Final_Weight, Quality_Score)\n",
            "\n",
            "ğŸ”¬ Testing XGBoost...\n",
            "  âœ… Predictions shape: (400, 2)\n",
            "  ğŸ“Š Average RÂ² Score: 0.9987 (Expected: â‰¥0.99)\n",
            "    Final_Weight: RÂ²=0.9986, RMSE=0.0404\n",
            "      Prediction range: [41.74, 47.38]\n",
            "      Actual range: [41.70, 47.45]\n",
            "    Quality_Score: RÂ²=0.9988, RMSE=0.0716\n",
            "      Prediction range: [87.17, 98.95]\n",
            "      Actual range: [87.12, 99.13]\n",
            "  ğŸ“‹ Sample predictions:\n",
            "    Sample 1: [45.16889 94.39714]\n",
            "    Sample 2: [43.243603 94.96114 ]\n",
            "    Sample 3: [43.12462 95.60709]\n",
            "  ğŸ‰ XGBoost PASSED validation!\n",
            "\n",
            "ğŸ”¬ Testing Random Forest...\n",
            "  âœ… Predictions shape: (400, 2)\n",
            "  ğŸ“Š Average RÂ² Score: 0.6588 (Expected: â‰¥0.60)\n",
            "    Final_Weight: RÂ²=0.5716, RMSE=0.6995\n",
            "      Prediction range: [43.56, 45.77]\n",
            "      Actual range: [41.70, 47.45]\n",
            "    Quality_Score: RÂ²=0.7460, RMSE=1.0394\n",
            "      Prediction range: [90.15, 96.29]\n",
            "      Actual range: [87.12, 99.13]\n",
            "  ğŸ“‹ Sample predictions:\n",
            "    Sample 1: [44.9794126  93.81556881]\n",
            "    Sample 2: [44.24306549 94.36940729]\n",
            "    Sample 3: [43.99635888 94.18100937]\n",
            "  ğŸ‰ Random Forest PASSED validation!\n",
            "\n",
            "ğŸ”¬ Testing Neural Network...\n",
            "  âœ… Predictions shape: (400, 2)\n",
            "  ğŸ“Š Average RÂ² Score: 0.3065 (Expected: â‰¥0.30)\n",
            "    Final_Weight: RÂ²=-0.0651, RMSE=1.1030\n",
            "      Prediction range: [41.58, 47.18]\n",
            "      Actual range: [41.70, 47.45]\n",
            "    Quality_Score: RÂ²=0.6782, RMSE=1.1699\n",
            "      Prediction range: [86.44, 98.15]\n",
            "      Actual range: [87.12, 99.13]\n",
            "  ğŸ“‹ Sample predictions:\n",
            "    Sample 1: [45.37270142 93.17054824]\n",
            "    Sample 2: [45.20108438 94.53530653]\n",
            "    Sample 3: [44.70244745 94.56031223]\n",
            "  ğŸ‰ Neural Network PASSED validation!\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š VALIDATION SUMMARY:\n",
            "âœ… Models Passed: 3 (XGBoost, Random Forest, Neural Network)\n",
            "âŒ Models Failed: 0 (None)\n",
            "\n",
            "ğŸ‰ Validation completed! 3 models ready for saving.\n",
            "\n",
            "ğŸ”¬ Testing Ensemble Prediction...\n",
            "âœ… Ensemble prediction successful!\n",
            "ğŸ“Š Ensemble RÂ² Score: 0.8977\n",
            "ğŸ“‹ Ensemble Metrics:\n",
            "  Final_Weight: RÂ²=0.8600, RMSE=0.3999\n",
            "  Quality_Score: RÂ²=0.9354, RMSE=0.5243\n",
            "\n",
            "âœ… Model validation and testing completed!\n"
          ]
        }
      ],
      "source": [
        "# 6. Model Validation & Testing\n",
        "#\n",
        "# Before saving the models, we need to validate that they can actually make predictions on test data and produce meaningful results.\n",
        "\n",
        "print(\"ğŸ§ª VALIDATING MODELS BEFORE SAVING...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create a test dataset from the validation set\n",
        "test_features = X_val_split.copy()\n",
        "test_targets = y_val_split.copy()\n",
        "\n",
        "print(f\"ğŸ“Š Test Dataset: {test_features.shape[0]} samples, {test_features.shape[1]} features\")\n",
        "print(f\"ğŸ¯ Test Targets: {test_targets.shape[1]} targets ({', '.join(target_cols)})\")\n",
        "\n",
        "# Test each model\n",
        "models_to_test = {\n",
        "    'XGBoost': {\n",
        "        'model': xgb_model,\n",
        "        'scaler': None,\n",
        "        'expected_r2': 0.99  # Should be very high\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model': rf_model,\n",
        "        'scaler': None,\n",
        "        'expected_r2': 0.60  # Should be decent\n",
        "    },\n",
        "    'Neural Network': {\n",
        "        'model': nn_model,\n",
        "        'scaler': scaler_nn,\n",
        "        'expected_r2': 0.30  # Should be acceptable\n",
        "    }\n",
        "}\n",
        "\n",
        "validation_results = {}\n",
        "models_passed = []\n",
        "models_failed = []\n",
        "\n",
        "for model_name, model_info in models_to_test.items():\n",
        "    print(f\"\\nğŸ”¬ Testing {model_name}...\")\n",
        "    \n",
        "    try:\n",
        "        model = model_info['model']\n",
        "        scaler = model_info['scaler']\n",
        "        \n",
        "        # Prepare test data\n",
        "        if scaler:\n",
        "            test_features_scaled = scaler.transform(test_features)\n",
        "            predictions = model.predict(test_features_scaled)\n",
        "        else:\n",
        "            predictions = model.predict(test_features)\n",
        "        \n",
        "        # Validate prediction shape\n",
        "        if predictions.shape != test_targets.shape:\n",
        "            raise ValueError(f\"Prediction shape {predictions.shape} doesn't match target shape {test_targets.shape}\")\n",
        "        \n",
        "        # Calculate metrics for each target\n",
        "        target_metrics = {}\n",
        "        for i, target_name in enumerate(target_cols):\n",
        "            y_true = test_targets.iloc[:, i].values\n",
        "            y_pred = predictions[:, i]\n",
        "            \n",
        "            # Check for valid predictions\n",
        "            if np.any(np.isnan(y_pred)):\n",
        "                raise ValueError(f\"NaN values found in predictions for {target_name}\")\n",
        "            \n",
        "            if np.any(np.isinf(y_pred)):\n",
        "                raise ValueError(f\"Infinite values found in predictions for {target_name}\")\n",
        "            \n",
        "            # Calculate metrics\n",
        "            r2 = r2_score(y_true, y_pred)\n",
        "            mse = mean_squared_error(y_true, y_pred)\n",
        "            mae = mean_absolute_error(y_true, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            \n",
        "            target_metrics[target_name] = {\n",
        "                'r2_score': r2,\n",
        "                'mse': mse,\n",
        "                'mae': mae,\n",
        "                'rmse': rmse,\n",
        "                'prediction_range': (y_pred.min(), y_pred.max()),\n",
        "                'actual_range': (y_true.min(), y_true.max())\n",
        "            }\n",
        "        \n",
        "        # Calculate average RÂ² score\n",
        "        avg_r2 = np.mean([metrics['r2_score'] for metrics in target_metrics.values()])\n",
        "        \n",
        "        # Check if model meets minimum performance threshold\n",
        "        expected_r2 = model_info['expected_r2']\n",
        "        passed_threshold = avg_r2 >= expected_r2\n",
        "        \n",
        "        validation_results[model_name] = {\n",
        "            'passed': passed_threshold,\n",
        "            'avg_r2_score': avg_r2,\n",
        "            'target_metrics': target_metrics,\n",
        "            'predictions_shape': predictions.shape,\n",
        "            'sample_predictions': predictions[:3].tolist()\n",
        "        }\n",
        "        \n",
        "        print(f\"  âœ… Predictions shape: {predictions.shape}\")\n",
        "        print(f\"  ğŸ“Š Average RÂ² Score: {avg_r2:.4f} (Expected: â‰¥{expected_r2:.2f})\")\n",
        "        \n",
        "        for target, metrics in target_metrics.items():\n",
        "            print(f\"    {target}: RÂ²={metrics['r2_score']:.4f}, RMSE={metrics['rmse']:.4f}\")\n",
        "            print(f\"      Prediction range: [{metrics['prediction_range'][0]:.2f}, {metrics['prediction_range'][1]:.2f}]\")\n",
        "            print(f\"      Actual range: [{metrics['actual_range'][0]:.2f}, {metrics['actual_range'][1]:.2f}]\")\n",
        "        \n",
        "        print(f\"  ğŸ“‹ Sample predictions:\")\n",
        "        for i, pred in enumerate(predictions[:3]):\n",
        "            print(f\"    Sample {i+1}: {pred}\")\n",
        "        \n",
        "        if passed_threshold:\n",
        "            print(f\"  ğŸ‰ {model_name} PASSED validation!\")\n",
        "            models_passed.append(model_name)\n",
        "        else:\n",
        "            print(f\"  âŒ {model_name} FAILED validation (RÂ²={avg_r2:.4f} < {expected_r2:.2f})\")\n",
        "            models_failed.append(model_name)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ğŸ’¥ {model_name} FAILED with error: {str(e)}\")\n",
        "        models_failed.append(model_name)\n",
        "        validation_results[model_name] = {\n",
        "            'passed': False,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"ğŸ“Š VALIDATION SUMMARY:\")\n",
        "print(f\"âœ… Models Passed: {len(models_passed)} ({', '.join(models_passed) if models_passed else 'None'})\")\n",
        "print(f\"âŒ Models Failed: {len(models_failed)} ({', '.join(models_failed) if models_failed else 'None'})\")\n",
        "\n",
        "if not models_passed:\n",
        "    print(\"\\nğŸ’¥ CRITICAL ERROR: No models passed validation!\")\n",
        "    print(\"Please check the training process and data quality.\")\n",
        "    raise ValueError(\"No models passed validation\")\n",
        "\n",
        "print(f\"\\nğŸ‰ Validation completed! {len(models_passed)} models ready for saving.\")\n",
        "\n",
        "# Test ensemble prediction functionality\n",
        "print(\"\\nğŸ”¬ Testing Ensemble Prediction...\")\n",
        "\n",
        "try:\n",
        "    # Create a simple ensemble prediction\n",
        "    ensemble_predictions = []\n",
        "    ensemble_weights = []\n",
        "    \n",
        "    for model_name in models_passed:\n",
        "        model_info = models_to_test[model_name]\n",
        "        model = model_info['model']\n",
        "        scaler = model_info['scaler']\n",
        "        \n",
        "        # Make prediction\n",
        "        if scaler:\n",
        "            test_features_scaled = scaler.transform(test_features)\n",
        "            pred = model.predict(test_features_scaled)\n",
        "        else:\n",
        "            pred = model.predict(test_features)\n",
        "        \n",
        "        ensemble_predictions.append(pred)\n",
        "        ensemble_weights.append(validation_results[model_name]['avg_r2_score'])\n",
        "    \n",
        "    # Weighted average ensemble\n",
        "    weights = np.array(ensemble_weights) / np.sum(ensemble_weights)\n",
        "    ensemble_pred = np.zeros_like(ensemble_predictions[0])\n",
        "    \n",
        "    for i, pred in enumerate(ensemble_predictions):\n",
        "        ensemble_pred += weights[i] * pred\n",
        "    \n",
        "    # Calculate ensemble metrics\n",
        "    ensemble_metrics = {}\n",
        "    for i, target_name in enumerate(target_cols):\n",
        "        y_true = test_targets.iloc[:, i].values\n",
        "        y_pred = ensemble_pred[:, i]\n",
        "        \n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "        mse = mean_squared_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        \n",
        "        ensemble_metrics[target_name] = {\n",
        "            'r2_score': r2,\n",
        "            'rmse': rmse\n",
        "        }\n",
        "    \n",
        "    ensemble_avg_r2 = np.mean([metrics['r2_score'] for metrics in ensemble_metrics.values()])\n",
        "    \n",
        "    print(f\"âœ… Ensemble prediction successful!\")\n",
        "    print(f\"ğŸ“Š Ensemble RÂ² Score: {ensemble_avg_r2:.4f}\")\n",
        "    print(f\"ğŸ“‹ Ensemble Metrics:\")\n",
        "    for target, metrics in ensemble_metrics.items():\n",
        "        print(f\"  {target}: RÂ²={metrics['r2_score']:.4f}, RMSE={metrics['rmse']:.4f}\")\n",
        "    \n",
        "    # Add ensemble to validation results\n",
        "    validation_results['Ensemble'] = {\n",
        "        'passed': True,\n",
        "        'avg_r2_score': ensemble_avg_r2,\n",
        "        'target_metrics': ensemble_metrics,\n",
        "        'predictions_shape': ensemble_pred.shape,\n",
        "        'sample_predictions': ensemble_pred[:3].tolist()\n",
        "    }\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Ensemble prediction failed: {str(e)}\")\n",
        "    validation_results['Ensemble'] = {\n",
        "        'passed': False,\n",
        "        'error': str(e)\n",
        "    }\n",
        "\n",
        "print(\"\\nâœ… Model validation and testing completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "## 6. Save Models for Module 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ’¾ Saving validated models for Module 2...\n",
            "==================================================\n",
            "âœ… Saved XGBoost to gcFnB_pretrained_xgboost_20250824_065830.pkl\n",
            "   ğŸ“Š RÂ² Score: 0.9987\n",
            "âœ… Saved Random Forest to gcFnB_pretrained_random_forest_20250824_065830.pkl\n",
            "   ğŸ“Š RÂ² Score: 0.6588\n",
            "âœ… Saved Neural Network to gcFnB_pretrained_neural_network_20250824_065830.pkl\n",
            "   ğŸ“Š RÂ² Score: 0.3065\n",
            "\n",
            "ğŸ“Š Save Summary:\n",
            "âœ… Successfully saved: 3 models\n",
            "âŒ Failed to save: 0 models\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Object of type bool_ is not JSON serializable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m feature_file \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/processed/feature_columns_module2.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(feature_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 91\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Feature information saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Validation results included in feature file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: Object of type bool_ is not JSON serializable"
          ]
        }
      ],
      "source": [
        "# 7. Save Models for Module 2\n",
        "\n",
        "# Only save models that passed validation\n",
        "print(\"ğŸ’¾ Saving validated models for Module 2...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create timestamp for model files\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "# Prepare model metadata for validated models only\n",
        "models_to_save = {}\n",
        "\n",
        "if 'XGBoost' in models_passed:\n",
        "    models_to_save['xgboost'] = {\n",
        "        'model': xgb_model,\n",
        "        'scaler': None,\n",
        "        'metadata': {\n",
        "            'name': 'XGBoost',\n",
        "            'type': 'tree_based',\n",
        "            'metrics': validation_results['XGBoost']['target_metrics'],\n",
        "            'avg_r2_score': validation_results['XGBoost']['avg_r2_score'],\n",
        "            'training_timestamp': timestamp,\n",
        "            'validation_passed': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "if 'Random Forest' in models_passed:\n",
        "    models_to_save['random_forest'] = {\n",
        "        'model': rf_model,\n",
        "        'scaler': None,\n",
        "        'metadata': {\n",
        "            'name': 'Random Forest',\n",
        "            'type': 'tree_based',\n",
        "            'metrics': validation_results['Random Forest']['target_metrics'],\n",
        "            'avg_r2_score': validation_results['Random Forest']['avg_r2_score'],\n",
        "            'training_timestamp': timestamp,\n",
        "            'validation_passed': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "if 'Neural Network' in models_passed:\n",
        "    models_to_save['neural_network'] = {\n",
        "        'model': nn_model,\n",
        "        'scaler': scaler_nn,\n",
        "        'metadata': {\n",
        "            'name': 'Neural Network',\n",
        "            'type': 'neural',\n",
        "            'metrics': validation_results['Neural Network']['target_metrics'],\n",
        "            'avg_r2_score': validation_results['Neural Network']['avg_r2_score'],\n",
        "            'training_timestamp': timestamp,\n",
        "            'validation_passed': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Save models\n",
        "saved_models = []\n",
        "failed_saves = []\n",
        "\n",
        "for model_key, model_data in models_to_save.items():\n",
        "    model_path = MODEL_DIR_MODULE2 / f\"gcFnB_pretrained_{model_key}_{timestamp}.pkl\"\n",
        "    \n",
        "    try:\n",
        "        joblib.dump(model_data, model_path)\n",
        "        saved_models.append(model_key)\n",
        "        print(f\"âœ… Saved {model_data['metadata']['name']} to {model_path.name}\")\n",
        "        print(f\"   ğŸ“Š RÂ² Score: {model_data['metadata']['avg_r2_score']:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to save {model_key}: {str(e)}\")\n",
        "        failed_saves.append(model_key)\n",
        "\n",
        "print(f\"\\nğŸ“Š Save Summary:\")\n",
        "print(f\"âœ… Successfully saved: {len(saved_models)} models\")\n",
        "print(f\"âŒ Failed to save: {len(failed_saves)} models\")\n",
        "\n",
        "if not saved_models:\n",
        "    print(\"\\nğŸ’¥ CRITICAL ERROR: No models were saved!\")\n",
        "    raise ValueError(\"No models were saved\")\n",
        "\n",
        "# Save feature information\n",
        "feature_info = {\n",
        "    'feature_columns': X_train.columns.tolist(),\n",
        "    'target_columns': target_cols,\n",
        "    'training_timestamp': timestamp,\n",
        "    'validation_results': validation_results,\n",
        "    'models_passed': models_passed,\n",
        "    'models_failed': models_failed\n",
        "}\n",
        "\n",
        "feature_file = Path(\"../data/processed/feature_columns_module2.json\")\n",
        "with open(feature_file, 'w') as f:\n",
        "    json.dump(feature_info, f, indent=2)\n",
        "\n",
        "print(f\"âœ… Feature information saved to {feature_file.name}\")\n",
        "print(f\"âœ… Validation results included in feature file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 7. Training Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ğŸ‰ MODULE 2 TRAINING & VALIDATION COMPLETE!\n",
            "============================================================\n",
            "\n",
            "ğŸ† Final Model Rankings (Validated):\n",
            "         Model  RÂ² Score                  Type\n",
            "       XGBoost  0.998682          XGBRegressor\n",
            " Random Forest  0.658823 RandomForestRegressor\n",
            "Neural Network  0.306534          MLPRegressor\n",
            "\n",
            "ğŸ“Š Validation Summary:\n",
            "âœ… Models Passed: 3 (XGBoost, Random Forest, Neural Network)\n",
            "âŒ Models Failed: 0 (None)\n",
            "ğŸ’¾ Models Saved: 3 (xgboost, random_forest, neural_network)\n",
            "ğŸ† Best Model: XGBoost (RÂ² = 0.9987)\n",
            "ğŸ“ Models saved in: D:\\NoSQL\\Honeywell\\data\\model_module2\n",
            "â° Training timestamp: 20250824_065830\n",
            "\n",
            "âœ… Ready for Module 2 Integration!\n",
            "\n",
            "ğŸ“‹ Next Steps:\n",
            "  1. Start the web application: python app/app_v2.py\n",
            "  2. Access Module 2 for instant predictions\n",
            "  3. Upload process data and get predictions in < 1 second\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "#8. Training Summary\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ‰ MODULE 2 TRAINING & VALIDATION COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create comparison for validated models only\n",
        "validated_models = []\n",
        "for model_name in models_passed:\n",
        "    validated_models.append({\n",
        "        'Model': model_name,\n",
        "        'RÂ² Score': validation_results[model_name]['avg_r2_score'],\n",
        "        'Type': models_to_test[model_name]['model'].__class__.__name__\n",
        "    })\n",
        "\n",
        "if validated_models:\n",
        "    model_comparison = pd.DataFrame(validated_models).sort_values('RÂ² Score', ascending=False)\n",
        "    print(\"\\nğŸ† Final Model Rankings (Validated):\")\n",
        "    print(model_comparison.to_string(index=False))\n",
        "\n",
        "print(f\"\\nğŸ“Š Validation Summary:\")\n",
        "print(f\"âœ… Models Passed: {len(models_passed)} ({', '.join(models_passed) if models_passed else 'None'})\")\n",
        "print(f\"âŒ Models Failed: {len(models_failed)} ({', '.join(models_failed) if models_failed else 'None'})\")\n",
        "print(f\"ğŸ’¾ Models Saved: {len(saved_models)} ({', '.join(saved_models) if saved_models else 'None'})\")\n",
        "\n",
        "if models_passed:\n",
        "    best_model = max(models_passed, key=lambda x: validation_results[x]['avg_r2_score'])\n",
        "    best_score = validation_results[best_model]['avg_r2_score']\n",
        "    print(f\"ğŸ† Best Model: {best_model} (RÂ² = {best_score:.4f})\")\n",
        "\n",
        "print(f\"ğŸ“ Models saved in: {MODEL_DIR_MODULE2}\")\n",
        "print(f\"â° Training timestamp: {timestamp}\")\n",
        "\n",
        "print(\"\\nâœ… Ready for Module 2 Integration!\")\n",
        "print(\"\\nğŸ“‹ Next Steps:\")\n",
        "print(\"  1. Start the web application: python app/app_v2.py\")\n",
        "print(\"  2. Access Module 2 for instant predictions\")\n",
        "print(\"  3. Upload process data and get predictions in < 1 second\")\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gcvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
